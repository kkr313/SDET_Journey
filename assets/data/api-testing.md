# üåê Manual API Testing Complete Guide (Beginner to Advanced)

A **comprehensive guide** covering manual API testing from fundamentals to advanced concepts. This guide focuses on manual testing techniques, tools, and strategies for API testing. Written in simple language for testers at all levels - from beginners to experienced professionals.

---

## Table of Contents
1. [üß© Introduction to APIs](#-introduction-to-apis)
2. [üîç Understanding HTTP Basics](#-understanding-http-basics)
3. [üî¢ HTTP Status Codes](#-http-status-codes)
4. [üåê Browser Developer Tools for API Testing](#-browser-developer-tools-for-api-testing)
5. [üõ†Ô∏è Manual API Testing Tools](#Ô∏è-manual-api-testing-tools)
6. [Getting Started - Your First API Test](#getting-started---your-first-api-test)
7. [üèóÔ∏è Microservices & Modern Architecture](#Ô∏è-microservices--modern-architecture)
8. [API Testing Types](#api-testing-types)
9. [üß™ API Testing Fundamentals](#-api-testing-fundamentals)
10. [API Testing Tools](#api-testing-tools)
11. [Test Design and Strategy](#test-design-and-strategy)
12. [Advanced Testing Concepts](#advanced-testing-concepts)
13. [üß∞ Advanced API Testing Techniques](#-advanced-api-testing-techniques)
14. [üß± API Security Testing](#-api-security-testing)
15. [üìä Performance & Load Testing](#-performance--load-testing)
16. [üß† Interview Q&A for API Testing](#-interview-qa-for-api-testing)
17. [üìé Bonus Topics](#-bonus-topics)
18. [Conclusion](#conclusion)

---

## üß© Introduction to APIs

### What is an API?

**Simple Definition:** An API (Application Programming Interface) is like a waiter in a restaurant. You (the customer) don't go directly to the kitchen to get your food. Instead, you tell the waiter what you want, the waiter goes to the kitchen, gets your food, and brings it back to you.

**Technical Definition:** An API is a set of rules and protocols that allows different software applications to communicate with each other. It defines how requests should be made, what data formats to use, and how responses are structured.

**Real-World Example:**
When you use a weather app on your phone:
1. **You:** Open the app and search for "New York weather"
2. **App:** Sends a request to a weather API: "Give me weather data for New York"
3. **API:** Processes the request and sends back weather information
4. **App:** Displays the weather information to you

### Types of APIs

**1. REST (Representational State Transfer)**
- **What it is:** The most popular type of API, uses standard HTTP methods
- **Think of it as:** Like ordering from a menu - each item has a specific way to order it
- **Example:** GET /api/users/123 (get user with ID 123)
- **Why popular:** Simple, easy to understand, works with web browsers

**2. SOAP (Simple Object Access Protocol)**
- **What it is:** An older, more structured protocol with strict rules
- **Think of it as:** Like filling out a formal government form - everything must be exact
- **Example:** Used in banking and enterprise systems
- **Characteristics:** More secure but complex, uses XML format

**3. GraphQL**
- **What it is:** A query language that lets you request exactly what data you need
- **Think of it as:** Like a custom sandwich shop - you choose exactly what ingredients you want
- **Example:** Query { user(id: 123) { name, email } } - gets only name and email
- **Advantage:** Reduces data transfer, flexible queries

**Comparison Table:**

| Aspect | REST | SOAP | GraphQL |
|--------|------|------|---------|
| **Complexity** | Simple | Complex | Medium |
| **Learning Curve** | Easy | Steep | Medium |
| **Data Format** | JSON, XML | XML only | JSON |
| **Performance** | Fast | Slower | Very Fast |
| **Use Cases** | Web apps, mobile | Enterprise, banking | Modern apps, mobile |

### API vs Web Services

**API (Application Programming Interface):**
- **Broader concept:** Set of rules for software communication
- **Scope:** Can be used locally or over networks
- **Example:** Operating system APIs, library APIs

**Web Services:**
- **Specific type:** APIs that work over the internet
- **Scope:** Always network-based
- **Example:** Weather API, Payment API, Social media API

**Simple Analogy:**
- **API** = Communication rules (like language grammar)
- **Web Service** = Online communication using those rules (like video calling)

### API Architecture Basics

**1. Client-Server Architecture**
```
[Mobile App] ‚Üê‚Üí [API Server] ‚Üê‚Üí [Database]
   Client           Server        Storage
```

**2. Request-Response Cycle**
```
1. Client sends REQUEST ‚Üí Server
2. Server processes request
3. Server sends RESPONSE ‚Üê Client
4. Client displays result to user
```

**3. Stateless Nature**
- Each API request is independent
- Server doesn't remember previous requests
- Like asking directions - each question is separate

**4. Resource-Based URLs**
```
Good API Design:
- GET /api/users (get all users)
- GET /api/users/123 (get specific user)
- POST /api/users (create new user)
- PUT /api/users/123 (update user)
- DELETE /api/users/123 (delete user)
```

---

## üîç Understanding HTTP Basics

### HTTP Methods: The Verbs of the Internet

Think of HTTP methods like actions you can perform in a library:

**1. GET - "Show me something"**
- **Purpose:** Retrieve information
- **Like:** Looking at a book (doesn't change anything)
- **Example:** GET /api/books/123 (show me book #123)
- **Safe:** Yes (doesn't modify data)
- **Used for:** Fetching user profiles, product lists, search results

```bash
# Example GET request
GET /api/users/123
Host: example.com
```

**2. POST - "Create something new"**
- **Purpose:** Create new resources
- **Like:** Adding a new book to the library
- **Example:** POST /api/users (create new user account)
- **Safe:** No (creates new data)
- **Used for:** User registration, placing orders, uploading files

```bash
# Example POST request
POST /api/users
Content-Type: application/json

{
  "name": "John Doe",
  "email": "john@example.com"
}
```

**3. PUT - "Replace completely"**
- **Purpose:** Update entire resource
- **Like:** Replacing an entire page in a book
- **Example:** PUT /api/users/123 (replace all user data)
- **Safe:** No (modifies data)
- **Used for:** Complete profile updates, replacing documents

```bash
# Example PUT request
PUT /api/users/123
Content-Type: application/json

{
  "name": "John Smith",
  "email": "johnsmith@example.com",
  "age": 30
}
```

**4. PATCH - "Update partially"**
- **Purpose:** Update part of a resource
- **Like:** Correcting a word in a book
- **Example:** PATCH /api/users/123 (update only email)
- **Safe:** No (modifies data)
- **Used for:** Changing passwords, updating phone numbers

```bash
# Example PATCH request
PATCH /api/users/123
Content-Type: application/json

{
  "email": "newemail@example.com"
}
```

**5. DELETE - "Remove something"**
- **Purpose:** Delete resources
- **Like:** Removing a book from the library
- **Example:** DELETE /api/users/123 (delete user account)
- **Safe:** No (removes data)
- **Used for:** Account deletion, removing items from cart

```bash
# Example DELETE request
DELETE /api/users/123
```

### HTTP Request & Response Structure

**HTTP Request Structure:**
```
REQUEST LINE:    GET /api/users HTTP/1.1
HEADERS:         Host: example.com
                 Authorization: Bearer token123
                 Content-Type: application/json
BLANK LINE:      
BODY:            {"name": "John", "email": "john@example.com"}
```

**HTTP Response Structure:**
```
STATUS LINE:     HTTP/1.1 200 OK
HEADERS:         Content-Type: application/json
                 Server: nginx/1.18.0
                 Content-Length: 156
BLANK LINE:      
BODY:            {"id": 123, "name": "John", "email": "john@example.com"}
```

### Headers, Body, Query Params, Path Params

**1. Headers - "Metadata about the message"**
Think of headers like the envelope of a letter - they contain delivery information.

**Common Request Headers:**
```http
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
Content-Type: application/json
Accept: application/json
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)
```

**Common Response Headers:**
```http
Content-Type: application/json
Server: Apache/2.4.41
Cache-Control: no-cache
Set-Cookie: sessionId=abc123; HttpOnly
```

**2. Request Body - "The actual message"**
Think of the body like the letter inside the envelope.

**JSON Example:**
```json
{
  "firstName": "John",
  "lastName": "Doe",
  "email": "john.doe@example.com",
  "address": {
    "street": "123 Main St",
    "city": "New York",
    "zipCode": "10001"
  }
}
```

**3. Query Parameters - "Extra questions"**
Think of query params like asking "By the way, can you also tell me..."

**Format:** `?key1=value1&key2=value2`

**Examples:**
```
GET /api/users?page=2&limit=10&sort=name
GET /api/products?category=electronics&minPrice=100&maxPrice=500
GET /api/search?q=laptop&color=black&brand=dell
```

**4. Path Parameters - "Specific item identifier"**
Think of path params like a specific address.

**Examples:**
```
GET /api/users/123          (userId = 123)
GET /api/orders/456/items   (orderId = 456)
GET /api/posts/789/comments (postId = 789)
```

### MIME Types & Content-Type

**MIME Types** tell the receiver what type of data is being sent.

**Common MIME Types:**

| Content Type | MIME Type | Description |
|-------------|-----------|-------------|
| JSON | application/json | Most common for APIs |
| XML | application/xml | Structured data format |
| Form Data | application/x-www-form-urlencoded | HTML form submissions |
| File Upload | multipart/form-data | Uploading files |
| Plain Text | text/plain | Simple text |
| HTML | text/html | Web pages |
| Images | image/jpeg, image/png | Image files |

**Example with different Content-Types:**

**JSON Request:**
```http
POST /api/users
Content-Type: application/json

{
  "name": "John Doe",
  "email": "john@example.com"
}
```

**Form Data Request:**
```http
POST /api/users
Content-Type: application/x-www-form-urlencoded

name=John+Doe&email=john%40example.com
```

**File Upload Request:**
```http
POST /api/upload
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW

------WebKitFormBoundary7MA4YWxkTrZu0gW
Content-Disposition: form-data; name="file"; filename="document.pdf"
Content-Type: application/pdf

[PDF file content]
------WebKitFormBoundary7MA4YWxkTrZu0gW--
```

---

## üî¢ HTTP Status Codes

HTTP Status Codes are like return receipts - they tell you what happened to your request.

### HTTP Methods

| Method | Purpose | Idempotent | Safe |
|--------|---------|------------|------|
| **GET** | Retrieve data | ‚úÖ | ‚úÖ |
| **POST** | Create new resource | ‚ùå | ‚ùå |
| **PUT** | Update/Replace resource | ‚úÖ | ‚ùå |
| **PATCH** | Partial update | ‚ùå | ‚ùå |
| **DELETE** | Remove resource | ‚úÖ | ‚ùå |
| **HEAD** | Get headers only | ‚úÖ | ‚úÖ |
| **OPTIONS** | Get allowed methods | ‚úÖ | ‚úÖ |

### HTTP Status Codes

**Success (2xx):**
- **200 OK:** Request successful
- **201 Created:** Resource created successfully
- **202 Accepted:** Request accepted for processing
- **204 No Content:** Successful with no response body

**Client Error (4xx):**
- **400 Bad Request:** Invalid request syntax
- **401 Unauthorized:** Authentication required
- **403 Forbidden:** Access denied
- **404 Not Found:** Resource not found
- **409 Conflict:** Resource conflict
- **422 Unprocessable Entity:** Validation errors
- **429 Too Many Requests:** Rate limit exceeded

**Server Error (5xx):**
- **500 Internal Server Error:** Server error
- **502 Bad Gateway:** Invalid response from upstream
- **503 Service Unavailable:** Server temporarily unavailable
- **504 Gateway Timeout:** Upstream server timeout

### Understanding Status Code Categories

**Think of status codes like traffic lights:**
- **1xx (100-199)** = Yellow light - "Wait, processing..."
- **2xx (200-299)** = Green light - "Success! Go ahead"
- **3xx (300-399)** = Yellow with arrow - "Redirect, go this way"
- **4xx (400-499)** = Red light - "Stop! You made a mistake"
- **5xx (500-599)** = Broken traffic light - "Server problem"

### 1xx ‚Äì Informational Responses

These are rare and mainly used in specific protocols.

**100 Continue**
- **Meaning:** "Keep sending your request"
- **When used:** Large file uploads
- **QA Scenario:** Test file upload APIs to ensure proper handling
- **Example:** Client asks "Can I upload this 100MB file?" Server responds "100 Continue"

**101 Switching Protocols**
- **Meaning:** "I'm switching to a different protocol"
- **When used:** WebSocket connections
- **QA Scenario:** Test real-time chat applications
- **Example:** HTTP upgrading to WebSocket for live chat

### 2xx ‚Äì Success Responses

**200 OK**
- **Meaning:** "Everything worked perfectly"
- **Most common:** Used for successful GET, PUT, PATCH requests
- **QA Scenarios to Test:**
  - Successful user login
  - Retrieving user profile
  - Updating user information
  - Search results found

```http
GET /api/users/123
Response: 200 OK
{
  "id": 123,
  "name": "John Doe",
  "email": "john@example.com"
}
```

**201 Created**
- **Meaning:** "Successfully created new resource"
- **When used:** Successful POST requests
- **QA Scenarios to Test:**
  - User registration
  - Creating new blog post
  - Adding item to shopping cart
  - Uploading new file

```http
POST /api/users
Response: 201 Created
Location: /api/users/124
{
  "id": 124,
  "name": "Jane Smith",
  "email": "jane@example.com"
}
```

**202 Accepted**
- **Meaning:** "I got your request, processing it later"
- **When used:** Asynchronous operations
- **QA Scenarios to Test:**
  - Bulk data import
  - Email sending
  - Report generation
  - Video processing

**204 No Content**
- **Meaning:** "Success, but no data to return"
- **When used:** Successful DELETE, some PUT operations
- **QA Scenarios to Test:**
  - Deleting user account
  - Removing item from cart
  - Updating settings (no response needed)

```http
DELETE /api/users/123
Response: 204 No Content
(empty body)
```

### 3xx ‚Äì Redirection Responses

**301 Moved Permanently**
- **Meaning:** "This resource moved to a new address forever"
- **QA Scenarios to Test:**
  - API versioning (v1 ‚Üí v2)
  - Domain changes
  - URL restructuring

**302 Found (Temporary Redirect)**
- **Meaning:** "Temporarily moved, use new address for now"
- **QA Scenarios to Test:**
  - Maintenance mode redirects
  - A/B testing redirects
  - Load balancing

**304 Not Modified**
- **Meaning:** "Content hasn't changed since last request"
- **QA Scenarios to Test:**
  - Caching behavior
  - Performance optimization
  - Bandwidth saving

### 4xx ‚Äì Client Error Responses

These are YOUR fault (client's fault) - you sent a bad request.

**400 Bad Request**
- **Meaning:** "Your request doesn't make sense"
- **Common causes:** Invalid JSON, missing required fields, wrong data types
- **QA Scenarios to Test:**
  ```json
  // Missing required field
  POST /api/users
  {
    "name": "John"
    // Missing required email field
  }
  Response: 400 Bad Request
  {
    "error": "Email is required"
  }
  
  // Invalid email format
  POST /api/users
  {
    "name": "John",
    "email": "invalid-email"
  }
  Response: 400 Bad Request
  {
    "error": "Invalid email format"
  }
  
  // Invalid JSON syntax
  POST /api/users
  {
    "name": "John",
    "email": "john@example.com",  // Extra comma
  }
  Response: 400 Bad Request
  ```

**401 Unauthorized**
- **Meaning:** "Who are you? Please authenticate"
- **When:** Missing or invalid credentials
- **QA Scenarios to Test:**
  ```http
  # No authentication
  GET /api/profile
  Response: 401 Unauthorized
  
  # Invalid token
  GET /api/profile
  Authorization: Bearer invalid_token
  Response: 401 Unauthorized
  
  # Expired token
  GET /api/profile
  Authorization: Bearer expired_token
  Response: 401 Unauthorized
  ```

**403 Forbidden**
- **Meaning:** "I know who you are, but you can't do this"
- **When:** Insufficient permissions
- **QA Scenarios to Test:**
  ```http
  # Regular user trying to access admin endpoint
  GET /api/admin/users
  Authorization: Bearer user_token
  Response: 403 Forbidden
  
  # User trying to delete another user's data
  DELETE /api/users/456
  Authorization: Bearer user_123_token
  Response: 403 Forbidden
  ```

**404 Not Found**
- **Meaning:** "I can't find what you're looking for"
- **When:** Resource doesn't exist
- **QA Scenarios to Test:**
  ```http
  # Non-existent user
  GET /api/users/99999
  Response: 404 Not Found
  
  # Wrong endpoint
  GET /api/usrs/123  (typo in 'users')
  Response: 404 Not Found
  
  # Deleted resource
  GET /api/posts/123  (post was deleted)
  Response: 404 Not Found
  ```

**405 Method Not Allowed**
- **Meaning:** "This endpoint exists, but doesn't support this HTTP method"
- **QA Scenarios to Test:**
  ```http
  # Trying to DELETE on read-only endpoint
  DELETE /api/reports/123
  Response: 405 Method Not Allowed
  Allow: GET, POST
  
  # Trying to POST to list endpoint that only allows GET
  POST /api/categories
  Response: 405 Method Not Allowed
  ```

**409 Conflict**
- **Meaning:** "Your request conflicts with current state"
- **QA Scenarios to Test:**
  ```http
  # Duplicate email registration
  POST /api/users
  {
    "email": "existing@example.com"
  }
  Response: 409 Conflict
  {
    "error": "Email already exists"
  }
  
  # Editing outdated resource
  PUT /api/documents/123
  If-Match: "old_version_id"
  Response: 409 Conflict
  ```

**422 Unprocessable Entity**
- **Meaning:** "I understand your request format, but the data is invalid"
- **QA Scenarios to Test:**
  ```http
  # Valid JSON, but business rule violation
  POST /api/users
  {
    "name": "John",
    "email": "john@example.com",
    "age": -5  // Invalid age
  }
  Response: 422 Unprocessable Entity
  {
    "errors": {
      "age": ["Age must be positive"]
    }
  }
  ```

**429 Too Many Requests**
- **Meaning:** "Slow down! You're making too many requests"
- **When:** Rate limiting triggered
- **QA Scenarios to Test:**
  ```http
  # Exceeded rate limit
  GET /api/search?q=test
  (after 100 requests in 1 minute)
  Response: 429 Too Many Requests
  Retry-After: 60
  {
    "error": "Rate limit exceeded. Try again in 60 seconds"
  }
  ```

### 5xx ‚Äì Server Error Responses

These are the SERVER'S fault - something went wrong on their end.

**500 Internal Server Error**
- **Meaning:** "Something broke on our server"
- **Common causes:** Code bugs, database errors, configuration issues
- **QA Scenarios to Test:**
  - Send data that causes server-side errors
  - Test with database connectivity issues
  - Verify error logging and monitoring

**502 Bad Gateway**
- **Meaning:** "I'm a proxy/gateway and got invalid response from upstream server"
- **QA Scenarios to Test:**
  - Microservices communication failures
  - Load balancer issues
  - API gateway problems

**503 Service Unavailable**
- **Meaning:** "Server is temporarily overloaded or under maintenance"
- **QA Scenarios to Test:**
  - Maintenance mode testing
  - Server overload scenarios
  - Scheduled downtime

**504 Gateway Timeout**
- **Meaning:** "I'm waiting for another server, but it's taking too long"
- **QA Scenarios to Test:**
  - Slow database queries
  - Third-party API timeout
  - Network connectivity issues

### Manual Testing Scenarios for Each Category

**1xx Testing Scenarios:**
- **100 Continue:** Test large file uploads in Postman - check if "Expect: 100-continue" header is sent
- **101 Switching Protocols:** Test WebSocket connections in browser Developer Tools

**2xx Testing Scenarios:**
- **200 OK:** Test successful GET requests - verify response contains expected data
- **201 Created:** Test POST requests - check Location header and response body contains new resource ID  
- **204 No Content:** Test DELETE requests - verify empty response body

**3xx Testing Scenarios:**
- **301 Moved Permanently:** Test old API endpoints - verify Location header points to new URL
- **304 Not Modified:** Test with If-None-Match header - verify response is empty when resource unchanged

**4xx Testing Scenarios:**
- **400 Bad Request:** Send invalid JSON or missing required fields
- **401 Unauthorized:** Send requests without authentication or with invalid tokens
- **403 Forbidden:** Use regular user token to access admin endpoints
- **404 Not Found:** Request non-existent resources (e.g., /api/users/999999)
- **429 Too Many Requests:** Make rapid successive requests to trigger rate limiting

**5xx Testing Scenarios:**
- **500 Internal Server Error:** Watch for server errors in browser Network tab
- **502 Bad Gateway:** Test during server maintenance or microservice failures
- **503 Service Unavailable:** Test during planned downtime
- **504 Gateway Timeout:** Test with very slow network conditions

### Status Code Testing Best Practices

**1. Test Expected Status Codes:**
- **CREATE operations:** Should return 201 Created with Location header
- **READ operations:** Should return 200 OK with resource data
- **UPDATE operations:** Should return 200 OK or 204 No Content
- **DELETE operations:** Should return 204 No Content or 200 OK

**2. Test Error Conditions:**
- Test invalid data formats (400 Bad Request)
- Test missing authentication (401 Unauthorized)  
- Test insufficient permissions (403 Forbidden)
- Test non-existent resources (404 Not Found)
- Test duplicate resource creation (409 Conflict)

**3. Validate Response Bodies for Error Codes:**
- Verify error responses contain helpful error messages
- Check error response structure is consistent
- Ensure sensitive information is not exposed in errors
- Test error message localization if applicable

**Manual Testing Tools for Status Codes:**
- **Postman:** Clear status code display with color coding
- **Browser Developer Tools:** Network tab shows status codes for all requests
- **cURL:** **Classification: Manual Testing Tool** - Command line utility for making HTTP requests
- **Insomnia:** Alternative to Postman with status code validation

### cURL (Command Line URL tool) - Manual Testing Classification

**Classification:** Manual Testing Tool

**What it is:** cURL is a command-line tool for transferring data with URLs, commonly used for manual API testing through terminal/command prompt.

**Manual Testing Benefits:**
- **Quick API Testing:** Test endpoints directly from command line without GUI tools
- **Script Integration:** Easy to integrate into shell scripts for batch testing
- **Lightweight:** No additional software installation required on most systems
- **Automation-Free Testing:** Perfect for manual, one-off API requests
- **Debugging:** Excellent for troubleshooting API issues with verbose output

**Manual Testing Usage Examples:**

**Basic GET Request:**
```bash
# Simple GET request
curl https://api.example.com/users

# GET with headers displayed
curl -i https://api.example.com/users

# GET with verbose output for debugging
curl -v https://api.example.com/users
```

**Authentication Testing:**
```bash
# Basic Authentication
curl -u username:password https://api.example.com/protected

# Bearer Token Authentication
curl -H "Authorization: Bearer your_token_here" https://api.example.com/users

# API Key Authentication
curl -H "X-API-Key: your_api_key" https://api.example.com/data
```

**POST Request Testing:**
```bash
# POST with JSON data
curl -X POST https://api.example.com/users \
  -H "Content-Type: application/json" \
  -d '{"name": "John Doe", "email": "john@example.com"}'

# POST with form data
curl -X POST https://api.example.com/login \
  -d "username=testuser&password=testpass"
```

**Manual Testing Scenarios with cURL:**
- ‚úÖ **Quick endpoint verification:** Test if API endpoints are accessible
- ‚úÖ **Authentication testing:** Verify different auth methods work correctly
- ‚úÖ **Header inspection:** Use -i flag to examine response headers
- ‚úÖ **Error debugging:** Use -v flag for detailed request/response information
- ‚úÖ **Status code validation:** Quickly check HTTP response codes
- ‚úÖ **Cross-platform testing:** Works on Windows, Mac, Linux, and Unix systems

**Why cURL is Ideal for Manual Testing:**
- **No setup required:** Available on most systems by default
- **Fast execution:** Immediate results without loading GUI applications
- **Precise control:** Exact control over headers, data, and request methods
- **Learning tool:** Helps understand HTTP protocol fundamentals
- **Documentation:** Easy to document API calls as simple command-line examples

---

## üåê Browser Developer Tools for API Testing

### What are Browser Developer Tools?

**Simple Definition:** Browser Developer Tools are built-in utilities in web browsers that help developers and testers inspect, debug, and analyze web applications and their API calls. Think of them as a "behind-the-scenes" window into how websites communicate with servers.

**Why Important for API Testing:**
- **See Real API Calls:** Watch actual requests your browser makes
- **Inspect Responses:** View complete response data and headers
- **Analyze Performance:** Check how long APIs take to respond
- **Debug Issues:** Identify what went wrong with API calls
- **Monitor Network Activity:** Track all communication between browser and servers

### Accessing Developer Tools

**Chrome/Edge:**
- **Method 1:** Press `F12` key
- **Method 2:** Right-click on page ‚Üí "Inspect" ‚Üí "Network" tab
- **Method 3:** Menu ‚Üí More Tools ‚Üí Developer Tools

**Firefox:**
- **Method 1:** Press `F12` key
- **Method 2:** Right-click ‚Üí "Inspect Element" ‚Üí "Network" tab
- **Method 3:** Menu ‚Üí Web Developer ‚Üí Network

**Safari:**
- Enable Developer menu first: Preferences ‚Üí Advanced ‚Üí "Show Develop menu"
- Develop ‚Üí Show Web Inspector ‚Üí Network tab

### Network Tab - Your API Testing Command Center

**What is the Network Tab?**
The Network tab shows all network requests made by a web page, including API calls, image loads, CSS files, and more. For API testing, this is your most powerful tool.

**Key Components:**

**1. Request List with Enhanced Columns:**
```
Name        Status   Type        Size    Time    Waterfall    Priority
/api/users    200    XHR         2.3KB   120ms   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     High
/api/login    401    XHR         156B    89ms    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       High  
/api/orders   200    Fetch       5.1KB   203ms   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Medium
/api/stats    304    XHR         0B      45ms    ‚ñà‚ñà‚ñà‚ñà         Low
```

**2. Advanced Network Tab Features:**
- **Request Initiator:** Shows what triggered each API call (script, user action, etc.)
- **Priority Column:** Displays browser's request prioritization
- **Protocol:** HTTP/1.1, HTTP/2, or HTTP/3 protocol information
- **Cache Status:** Shows if response came from cache or network

**3. Request Details Panel Tabs:**
- **Headers:** Complete request/response headers with copy functionality
- **Preview:** Formatted, searchable response data (JSON/XML/HTML)
- **Response:** Raw response content for debugging format issues
- **Timing:** Detailed waterfall breakdown with precise measurements
- **Cookies:** Request/response cookie information
- **Security:** SSL/TLS certificate and security details

**4. Network Tab Toolbar Options:**
- **Record Button:** Start/stop recording network activity
- **Clear Button:** Clear all recorded requests
- **Filter Row:** Show/hide specific request types
- **Search Box:** Find specific requests by URL, header, or content
- **Settings Gear:** Configure columns and preferences

**5. Network Conditions Simulation:**
- **Online:** Normal network speed
- **Fast 3G:** 1.6 Mbps down, 750 Kbps up, 562ms latency
- **Slow 3G:** 780 Kbps down, 330 Kbps up, 2000ms latency  
- **Offline:** No network connectivity
- **Custom:** Define your own speed profiles

### Understanding Network Tab Information

**1. Status Codes (Visual Indicators):**
- **Green (2xx):** Success - API worked correctly
- **Yellow (3xx):** Redirection - API redirected to another URL
- **Red (4xx/5xx):** Error - Something went wrong

**2. Request Types for APIs:**
- **XHR:** Traditional AJAX requests
- **Fetch:** Modern JavaScript fetch API calls
- **WebSocket:** Real-time communication
- **Document:** Page loads that might trigger APIs

**3. Size Information:**
- **Size:** Actual data transferred (compressed)
- **Content:** Original data size (uncompressed)
- **Useful for:** Identifying large responses that might slow down apps

### Timing Analysis in Browser Tools

**Understanding API Response Times:**

**1. Timing Tab Breakdown:**
```
Queueing:        2ms    (Waiting in browser queue)
Stalled:         0ms    (Browser delays)  
DNS Lookup:      15ms   (Finding server address)
Initial Connection: 45ms (Connecting to server)
SSL:            12ms   (Security handshake)
Request sent:    1ms    (Sending request)
TTFB:           89ms   (Time to First Byte)
Content Download: 23ms  (Downloading response)
Total:          187ms  (Complete request time)
```

**2. Detailed Timing Explanations:**
- **Queueing:** Browser waiting to process request (high = browser overloaded)
- **Stalled:** Browser stalling before sending request (high = connection limits)
- **DNS Lookup:** Converting domain to IP address (cache misses cause delays)
- **Initial Connection:** TCP handshake time (high = network latency)
- **SSL:** SSL/TLS negotiation time (high = certificate issues)
- **Request Sent:** Time to upload request data
- **TTFB (Time to First Byte):** Server processing time (most critical metric)
- **Content Download:** Time to download response (large = big payloads)

**3. Performance Red Flags & Troubleshooting:**
- **High TTFB (>500ms):** 
  - Server processing issues
  - Database performance problems
  - Overloaded backend services
- **Long DNS Lookup (>100ms):** 
  - DNS server issues
  - First-time domain resolution
  - Geographic DNS latency
- **Slow Content Download (>1s for small responses):** 
  - Large response payloads
  - Network bandwidth issues
  - Missing compression
- **High Queueing (>50ms):**
  - Too many concurrent requests
  - Browser connection limits
  - Need for request optimization

**4. Waterfall Chart Analysis:**
```
Visual Timeline:
‚îú‚îÄ‚îÄ DNS    ‚ñà‚ñà‚ñà‚ñà
‚îú‚îÄ‚îÄ Connect     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚îú‚îÄ‚îÄ SSL              ‚ñà‚ñà‚ñà‚ñà
‚îú‚îÄ‚îÄ Wait                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚îî‚îÄ‚îÄ Receive                                   ‚ñà‚ñà‚ñà‚ñà

Timeline Analysis:
- Gaps between requests = processing delays
- Overlapping bars = parallel processing
- Long bars = performance bottlenecks
```

**5. Network Log Insights:**
- **Priority Column:** Shows request priority (High/Medium/Low)
- **Initiator Column:** Shows what triggered the request
- **Size vs Transferred:** Actual vs compressed data size
- **Cache Status:** Hit/Miss information

### Filtering and Searching API Calls

**Advanced Filtering Options:**

**1. Filter by Request Type:**
- **XHR:** Traditional AJAX API calls
- **Fetch:** Modern JavaScript fetch API calls  
- **WS:** WebSocket real-time connections
- **Doc:** Document requests (HTML pages)
- **CSS:** Stylesheet requests
- **JS:** JavaScript file requests
- **Img:** Image requests
- **Font:** Font file requests
- **Other:** Miscellaneous request types

**2. Status Code Filtering:**
- **Green (2xx):** Successful requests
- **Yellow (3xx):** Redirect responses  
- **Red (4xx):** Client errors (400, 401, 403, 404)
- **Red (5xx):** Server errors (500, 502, 503)
- **Gray:** Cancelled or pending requests

**3. Advanced Search Techniques:**
```
Search Examples:
- method:POST              ‚Üí Find all POST requests
- status-code:404          ‚Üí Find all 404 errors
- domain:api.example.com   ‚Üí Find requests to specific domain
- larger-than:1M           ‚Üí Find requests larger than 1MB
- mime-type:application/json ‚Üí Find JSON responses
- has-response-header:cors ‚Üí Find CORS-enabled responses
- url:*/users/*           ‚Üí Find all user-related endpoints
```

**4. Time-Based Filtering:**
- **Duration:** Filter by request duration (e.g., >2s)
- **Timeline:** Select specific time ranges
- **Waterfall:** Visual timeline filtering

**5. Size-Based Filtering:**
- **Response Size:** Filter by response payload size
- **Request Size:** Filter by request payload size
- **Total Size:** Combined request + response size

**Manual Testing Search Strategies:**

**Finding API Patterns:**
```
Common Search Patterns:
- /api/                    ‚Üí All API endpoints
- .json                    ‚Üí JSON responses
- auth                     ‚Üí Authentication-related requests
- error                    ‚Üí Error-related requests
- /v1/ OR /v2/            ‚Üí Version-specific APIs
```

**Debugging Failed Requests:**
```
Error Investigation:
1. Filter by status-code:400
2. Search for specific error terms
3. Look at request/response headers
4. Check timing for timeout issues
5. Examine payload for malformed data
```

**Performance Analysis:**
```
Performance Investigations:
1. Filter by larger-than:100K (large responses)
2. Sort by Time column (longest first)
3. Look for duplicate requests
4. Check for unnecessary API calls
5. Identify slow endpoints
```

**Security Testing:**
```
Security Checks:
1. Search for "password" in requests
2. Look for unencrypted HTTP calls
3. Check for exposed API keys
4. Verify authentication headers
5. Monitor for sensitive data in URLs
```

**Quick Filter Shortcuts:**
- **Ctrl+F (Cmd+F):** Open search box
- **Ctrl+Shift+F:** Search in all files
- **Ctrl+E:** Clear all filters
- **F5:** Refresh and clear network log
- **Ctrl+R:** Reload while preserving log

**Regular Expression Searches:**
```javascript
// Enable regex in search box with forward slashes
/api\/v[1-2]\/users/       ‚Üí Find API v1 or v2 user endpoints
/\d{3,4}\/                 ‚Üí Find endpoints with 3-4 digit IDs
/(login|auth|token)/       ‚Üí Find authentication-related calls
```

**Practical Search Examples:**

**1. Find All Failed API Calls:**
```
Steps:
1. Clear network log
2. Perform test actions
3. Filter: status-code:4* OR status-code:5*
4. Analyze failure patterns
```

**2. Identify Slow API Endpoints:**
```
Steps:
1. Sort by Time column (descending)
2. Look for requests >2 seconds
3. Check if consistent or intermittent
4. Analyze timing breakdown
```

**3. Find Authentication Issues:**
```
Search terms: "401", "403", "unauthorized", "forbidden"
Then check:
- Missing authorization headers
- Expired tokens
- Incorrect token format
```

**4. Monitor Real-time API Calls:**
```
Setup:
1. Keep Network tab open
2. Enable "Preserve log"
3. Use real-time filtering
4. Watch patterns as they happen
```

### Headers Analysis

**Request Headers - What Browser Sends:**
```
Accept: application/json
Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGc...
Content-Type: application/json
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)
Referer: https://myapp.com/dashboard
```

**Response Headers - What Server Sends Back:**
```
Content-Type: application/json
Cache-Control: no-cache
Access-Control-Allow-Origin: *
X-Rate-Limit-Remaining: 98
Set-Cookie: session_id=abc123; HttpOnly
```

**What to Check:**
- **Authorization headers:** Verify correct tokens are sent
- **Content-Type:** Ensure proper data format
- **CORS headers:** Check cross-origin permissions
- **Rate limiting headers:** Monitor API usage limits
- **Cache headers:** Understand caching behavior

### Response Analysis

**1. Preview Tab:**
- Shows formatted JSON/XML responses
- Easy to read and understand
- Automatically pretty-prints data

**2. Response Tab:**
- Raw response data
- Useful for debugging formatting issues
- Copy-paste friendly

**3. What to Look For:**
- **Data completeness:** All expected fields present
- **Data accuracy:** Values make sense
- **Error messages:** Clear error descriptions
- **Response structure:** Consistent format

### Console Tab for API Debugging

**What is the Console Tab?**
The console shows JavaScript errors, warnings, and logs. Many web applications log API-related information here, making it invaluable for manual API testing.

**Common API-Related Console Messages:**
```javascript
// Successful API call
‚úì User data loaded successfully
‚úì API Response: {users: 10, status: "ok"}

// API errors  
‚ùå Failed to load user data: 401 Unauthorized
‚ùå CORS policy blocked request to api.example.com
‚ùå Network Error: Failed to fetch
‚ùå API Error: Rate limit exceeded (429)

// Network errors
‚ùå TypeError: Failed to fetch
‚ùå Network request failed
‚ùå Timeout of 5000ms exceeded
```

**Manual Testing with Console Commands:**
```javascript
// 1. Test API calls directly in console
fetch('/api/users')
  .then(response => response.json())
  .then(data => console.log('Users:', data))
  .catch(error => console.error('Error:', error));

// 2. Check authentication status
console.log('Auth token:', localStorage.getItem('authToken'));
console.log('Session ID:', document.cookie);

// 3. Test different HTTP methods
fetch('/api/users', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ name: 'Test User', email: 'test@example.com' })
})
.then(response => console.log('Status:', response.status));

// 4. Monitor API response times
console.time('API Call');
fetch('/api/users').then(() => console.timeEnd('API Call'));

// 5. Test error handling
fetch('/api/nonexistent').catch(error => console.log('Caught error:', error));
```

**Debugging Techniques:**
```javascript
// Check if API endpoints exist
console.log('Current page:', window.location.href);
console.log('Available APIs:', window.API_ENDPOINTS); // If exposed

// Inspect network failures
window.addEventListener('error', (e) => {
  console.log('Network error detected:', e);
});

// Monitor XHR/Fetch requests
let originalFetch = window.fetch;
window.fetch = function(...args) {
  console.log('Fetch called:', args[0]);
  return originalFetch.apply(this, args);
};
```

**Console Error Analysis:**
- **CORS Errors:** Cross-origin issues requiring server configuration
- **401/403 Errors:** Authentication/authorization problems
- **Network Errors:** Connection, timeout, or DNS issues
- **Parse Errors:** Invalid JSON response format
- **Uncaught Exceptions:** JavaScript errors affecting API calls

### Application Tab for API-Related Storage

**What is the Application Tab?**
The Application tab provides access to browser storage and cached data that APIs often use for authentication, caching, and state management.

**Storage Types to Check:**

**1. Local Storage:**
- **Purpose:** Persistent data storage for the domain
- **Common API Data:** 
  - Authentication tokens (JWT, session tokens)
  - User preferences and settings
  - Cached API responses
  - Application configuration
- **Manual Testing:**
  - Check if tokens expire properly
  - Verify sensitive data isn't stored in plain text
  - Test data persistence across browser sessions

**2. Session Storage:**
- **Purpose:** Temporary data for the current session
- **Common API Data:**
  - Temporary authentication states
  - Form data before API submission
  - Session-specific cache
- **Manual Testing:**
  - Verify data clears when tab closes
  - Test session timeout behavior
  - Check data isolation between tabs

**3. Cookies:**
- **Purpose:** Small data pieces sent with API requests
- **Common API Data:**
  - Session identifiers
  - Authentication cookies
  - CSRF tokens
  - User tracking data
- **Manual Testing:**
  - Check HTTPOnly and Secure flags
  - Verify proper expiration dates
  - Test SameSite attribute behavior

**4. IndexedDB:**
- **Purpose:** Large-scale client-side storage
- **Common API Data:**
  - Cached API responses
  - Offline data storage
  - Large datasets for performance
- **Manual Testing:**
  - Test offline functionality
  - Verify data synchronization
  - Check storage quotas

**5. Cache Storage (Service Workers):**
- **Purpose:** Programmatic cache management
- **Common API Data:**
  - Cached API responses
  - Offline functionality data
- **Manual Testing:**
  - Test cache invalidation
  - Verify offline behavior
  - Check cache size limits

**Common Issues to Find:**

**Security Issues:**
- **Plain Text Passwords:** Check if passwords are stored unencrypted
- **Sensitive Data Exposure:** Look for API keys, personal data in storage
- **Missing Security Flags:** Cookies without HTTPOnly, Secure flags
- **XSS Vulnerabilities:** Scripts accessing sensitive storage data

**Performance Issues:**
- **Storage Bloat:** Too much cached data slowing down the app
- **Memory Leaks:** Data not being cleaned up properly
- **Quota Exceeded:** Storage limits being reached

**Functional Issues:**
- **Expired Tokens:** Authentication tokens not being refreshed
- **Stale Cache:** Old API responses not being updated
- **Cross-Tab Issues:** Data not syncing between browser tabs
- **Storage Conflicts:** Multiple apps using same storage keys

**Manual Testing Workflow:**

**1. Before Testing:**
```javascript
// Clear all storage in Console
localStorage.clear();
sessionStorage.clear();
// Clear cookies programmatically or via DevTools
```

**2. During API Testing:**
- Monitor storage changes after each API call
- Check if authentication tokens are stored securely
- Verify data persistence rules
- Test storage behavior during network failures

**3. After Testing:**
- Verify cleanup of temporary data
- Check for data leaks across sessions
- Test storage recovery after crashes

**Browser Storage Analysis Commands:**
```javascript
// Inspect Local Storage
console.log('Local Storage:', Object.entries(localStorage));

// Check Session Storage
console.log('Session Storage:', Object.entries(sessionStorage));

// Analyze Cookies
console.log('Cookies:', document.cookie);

// Check IndexedDB databases
indexedDB.databases().then(databases => 
  console.log('IndexedDB:', databases)
);

// Monitor storage events
window.addEventListener('storage', (e) => {
  console.log('Storage changed:', e.key, e.newValue);
});
```

### Throttling Network for Performance Testing

**What is Network Throttling?**
Browser tools let you simulate slower network conditions to test how your application behaves with slow APIs.

**How to Enable:**
1. Open Network tab
2. Click network conditions dropdown (usually shows "Online")
3. Select different speeds:
   - **Fast 3G:** Simulates mobile networks
   - **Slow 3G:** Very slow connections
   - **Offline:** No network connection

**What to Test:**
- Loading states during slow API calls
- Timeout behavior
- Error handling when network fails
- User experience with delayed responses

### Security Analysis in Browser Tools

**1. Security Tab:**
- Shows SSL/TLS certificate information
- Verifies secure connections
- Identifies mixed content issues

**2. What to Check:**
- **HTTPS usage:** All API calls should use HTTPS
- **Certificate validity:** No expired or invalid certificates
- **Mixed content:** No HTTP calls from HTTPS pages
- **Secure headers:** Proper security headers present

### Common Browser API Testing Scenarios

**Scenario 1: Login Flow Testing**
1. Open Network tab
2. Perform login
3. Check:
   - Login request shows correct credentials (but encrypted)
   - Response includes authentication token
   - Subsequent requests include authorization headers
   - No sensitive data in URLs

**Scenario 2: Form Submission Testing**
1. Fill out a form
2. Submit it
3. Monitor:
   - Correct data being sent
   - Proper HTTP method (POST/PUT)
   - Response indicates success/failure
   - Page updates appropriately

**Scenario 3: Real-time Feature Testing**
1. Look for WebSocket connections
2. Monitor message exchange
3. Check:
   - Connection establishes successfully
   - Messages sent and received
   - Connection stays alive
   - Proper reconnection on failures

### Browser Extensions for API Testing

**Popular Extensions:**

**1. Postman Interceptor:**
- Captures browser requests in Postman
- Syncs cookies and headers
- Enables testing with browser context

**2. REST Client:**
- Simple API testing within browser
- No additional software needed
- Good for quick tests

**3. JSON Formatter:**
- Makes JSON responses readable
- Syntax highlighting
- Collapsible objects

**4. CORS Unblock:**
- **Classification:** Manual Testing Tool
- Temporarily disables CORS for testing
- **Manual Usage:** Browser extension for testing cross-origin requests during development
- **Warning:** Only use for testing, never in production
- **Manual Testing Benefits:** Allows testing APIs from different domains without server configuration changes

### Best Practices for Browser API Testing

**1. Before Testing:**
- Clear browser cache and cookies
- Disable browser extensions that might interfere
- Open private/incognito window for clean testing

**2. During Testing:**
- Keep Network tab open
- Watch for errors in Console tab
- Note timing patterns
- Save important requests for documentation

**3. After Testing:**
- Export HAR files for sharing with developers
- Screenshot important findings
- Document any inconsistencies
- Clear test data from browser storage

**4. Documentation:**
- Record request/response examples
- Note any browser-specific behavior
- Document performance characteristics
- Save timing information for baseline comparisons

---

## üõ†Ô∏è Manual API Testing Tools

### Understanding Security in APIs

**Simple Analogy:** Think of API authentication like a hotel key card system:
- **Authentication:** Proves you are who you say you are (showing your ID at check-in)
- **Authorization:** Determines what you're allowed to do (your key card only opens your room, not the penthouse)

### Authentication vs Authorization

| **Authentication** | **Authorization** |
|-------------------|-------------------|
| **"Who are you?"** | **"What can you do?"** |
| Verifies identity | Controls access |
| Login process | Permission checking |
| User credentials | User roles/permissions |

### 1. Basic Authentication

**What it is:** The simplest form of authentication - sending username and password with every request.

**How it works:**
1. Client sends username:password encoded in Base64
2. Server validates credentials
3. Server responds with success/failure

**Example:**
```http
GET /api/users
Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=
```

**Base64 Encoding:**
```javascript
// JavaScript example
const credentials = btoa("username:password");
// Result: dXNlcm5hbWU6cGFzc3dvcmQ=
```

**Manual Testing Approaches:**

**Using Postman:**
1. Create new request to `https://api.example.com/users`
2. Go to Authorization tab ‚Üí Select "Basic Auth"
3. Enter username and password
4. Send request and verify 200 status code
5. Test with wrong credentials and verify 401 status

**Using Browser Developer Tools:**
1. Open Network tab
2. Make API call from JavaScript console:
```javascript
fetch('https://api.example.com/users', {
    headers: {
        'Authorization': 'Basic ' + btoa('username:password')
    }
})
.then(response => console.log('Status:', response.status))
```

**Using cURL Commands:**
```bash
# Valid credentials
curl -u username:password https://api.example.com/users

# Invalid credentials 
curl -u wrong:credentials https://api.example.com/users
```

**Pros:**
- Simple to implement
- Supported by all HTTP clients
- Good for internal APIs

**Cons:**
- Credentials sent with every request
- Not secure over HTTP (needs HTTPS)
- No expiration mechanism

### 2. API Key Authentication

**What it is:** A unique identifier that acts like a password for your application.

**Real-World Example:** Like a library card - it identifies you and what you're allowed to borrow.

**How it works:**
1. Developer registers and gets an API key
2. API key is sent with each request
3. Server validates the key and processes request

**Common Methods:**
```http
# Method 1: Query Parameter
GET /api/users?api_key=abc123xyz

# Method 2: Header
GET /api/users
X-API-Key: abc123xyz

# Method 3: Custom Header
GET /api/users
Authorization: ApiKey abc123xyz
```

**Manual Testing Approaches:**

**Using Postman:**
1. Create new request to `https://api.example.com/data`
2. Add API key in Headers: `X-API-Key: valid_api_key`
3. Send request and verify 200 status code
4. Test scenarios:
   - Invalid key: Change value to `invalid_key` ‚Üí Expect 401
   - Missing key: Remove header completely ‚Üí Expect 401
   - Wrong location: Put key in query params instead ‚Üí Verify behavior

**Using Browser Developer Tools:**
```javascript
// Test with valid API key
fetch('https://api.example.com/data', {
    headers: {
        'X-API-Key': 'valid_api_key'
    }
})
.then(response => console.log('Valid key status:', response.status))

// Test with invalid API key
fetch('https://api.example.com/data', {
    headers: {
        'X-API-Key': 'invalid_key'
    }
})
.then(response => console.log('Invalid key status:', response.status))
```

**Using cURL:**
```bash
# Valid API key
curl -H "X-API-Key: valid_api_key" https://api.example.com/data

# Invalid API key
curl -H "X-API-Key: invalid_key" https://api.example.com/data

# Missing API key
curl https://api.example.com/data
```

**QA Test Scenarios:**
- Valid API key ‚úÖ
- Invalid API key ‚ùå
- Expired API key ‚ùå
- Missing API key ‚ùå
- API key in wrong location ‚ùå
- Rate limiting with API key üìä

### 3. Bearer Token Authentication

**What it is:** A security token that "bears" the authentication information.

**Analogy:** Like a wristband at a music festival - shows you paid for entry and which areas you can access.

**How it works:**
1. Client authenticates and receives a token
2. Token is sent in the Authorization header
3. Server validates token and processes request

**Example:**
```http
GET /api/protected-resource
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

**Testing Bearer Tokens:**

**Manual Testing with Postman:**
1. Set Authorization type to "Bearer Token"
2. Paste token in the Token field
3. Send request and verify 200 OK response
4. Test with expired/invalid token and verify 401 Unauthorized

**Manual Testing with Browser Developer Tools:**
1. Open Network tab
2. Look for Authorization header in requests
3. Verify token format starts with "Bearer "
4. Check response for authentication errors

**Test Scenarios:**
- Valid token: Should return 200 OK
- Expired token: Should return 401 Unauthorized  
- Invalid format token: Should return 401 Unauthorized
- Missing token: Should return 401 Unauthorized

### 4. JWT (JSON Web Tokens) - Detailed Format Guide

**What it is:** A compact, URL-safe token that contains user information and claims.

**JWT Structure Explained:**
JWT has three parts separated by dots: `header.payload.signature`

**1. Header (Base64URL encoded):**
```json
{
  "alg": "HS256",     // Algorithm used for signing
  "typ": "JWT"        // Token type
}
```

**2. Payload (Base64URL encoded):**
```json
{
  "sub": "1234567890",        // Subject (user ID)
  "name": "John Doe",         // Custom claim
  "iat": 1516239022,          // Issued at (timestamp)
  "exp": 1516242622,          // Expiration time (timestamp)
  "aud": "your-app",          // Audience
  "iss": "your-auth-server",  // Issuer
  "jti": "unique-token-id"    // JWT ID (unique identifier)
}
```

**3. Signature:**
```
HMACSHA256(
  base64UrlEncode(header) + "." +
  base64UrlEncode(payload),
  secret)
```

**Complete JWT Example:**
```
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyLCJleHAiOjE1MTYyNDI2MjIsImF1ZCI6InlvdXItYXBwIiwiaXNzIjoieW91ci1hdXRoLXNlcnZlciJ9.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c
```

**Manual JWT Testing with Browser Developer Tools:**

**1. Decoding JWT in Browser Console:**
```javascript
// Extract JWT from authorization header or local storage
const token = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...";

// Decode header and payload (not signature)
function decodeJWT(token) {
    const parts = token.split('.');
    const header = JSON.parse(atob(parts[0]));
    const payload = JSON.parse(atob(parts[1]));
    
    console.log('Header:', header);
    console.log('Payload:', payload);
    
    // Check expiration
    const now = Math.floor(Date.now() / 1000);
    const isExpired = payload.exp < now;
    console.log('Is Expired:', isExpired);
    
    return { header, payload, isExpired };
}

decodeJWT(token);
```

**2. JWT Claims Explained:**

| Claim | Description | Example |
|-------|-------------|---------|
| `iss` | Issuer - who created the token | "auth.example.com" |
| `sub` | Subject - whom the token refers to | "user123" |
| `aud` | Audience - who should accept the token | "api.example.com" |
| `exp` | Expiration time (Unix timestamp) | 1516242622 |
| `iat` | Issued at time (Unix timestamp) | 1516239022 |
| `nbf` | Not before time (Unix timestamp) | 1516239022 |
| `jti` | JWT ID - unique identifier | "abc123" |

**Manual JWT Testing Scenarios:**

**Test 1: Valid JWT**
- Use Postman or browser to send request with valid JWT
- Expected: 200 OK response

**Test 2: Expired JWT**
- Create JWT with past expiration time
- Expected: 401 Unauthorized

**Test 3: Malformed JWT**
- Send request with invalid JWT format
- Expected: 401 Unauthorized

**Test 4: Modified JWT**
- Change payload data and keep same signature
- Expected: 401 Unauthorized (signature verification fails)

**Test 5: Missing JWT**
- Send request without authorization header
- Expected: 401 Unauthorized

**Manual Testing Tools:**
- **jwt.io:** Online JWT decoder and debugger
- **Postman:** Test API endpoints with different JWT scenarios
- **Browser DevTools:** Inspect JWT in network requests and local storage

**JWT Testing Checklist:**
- ‚úÖ Token format validation (3 parts separated by dots)
- ‚úÖ Header contains correct algorithm and type
- ‚úÖ Payload contains required claims (sub, exp, etc.)
- ‚úÖ Token expiration is respected
- ‚úÖ Token signature is valid
- ‚úÖ Token audience matches your application
- ‚úÖ Token issuer is trusted
- ‚úÖ Token cannot be used before 'nbf' claim
- ‚úÖ Proper error handling for invalid tokens

### 5. OAuth 2.0

**What it is:** An authorization framework that lets applications access user data without getting passwords.

**Real-World Example:** Like valet parking - you give the valet a special key that only starts your car and has limited access, not your house keys.

**OAuth Flow (Simplified):**
1. **User** clicks "Login with Google" on your app
2. **Your App** redirects user to Google's authorization server
3. **User** logs into Google and grants permission
4. **Google** redirects back to your app with an authorization code
5. **Your App** exchanges the code for an access token
6. **Your App** uses the access token to access user's data

**OAuth 2.0 Flow Diagram:**
```
[User] ‚Üí [Your App] ‚Üí [Auth Server] ‚Üí [Resource Server]
   ‚Üì         ‚Üì           ‚Üì              ‚Üì
 Login ‚Üí Redirect ‚Üí Grant Access ‚Üí Return Data
```

**Manual Testing OAuth Flow:**

**Using Postman OAuth 2.0:**
1. Create new request ‚Üí Authorization tab
2. Select "OAuth 2.0" type
3. Configure OAuth details:
   - Grant Type: Authorization Code
   - Auth URL: `https://oauth-provider.com/auth`
   - Access Token URL: `https://oauth-provider.com/token`
   - Client ID: `your_client_id`
   - Client Secret: `your_client_secret`
4. Click "Get New Access Token"
5. Complete authorization flow in browser
6. Use received token for API requests

**Manual Browser Testing:**
1. Navigate to authorization URL:
   ```
   https://oauth-provider.com/auth?client_id=123&response_type=code&redirect_uri=your_app_url
   ```
2. Complete login and authorization
3. Capture authorization code from redirect URL
4. Use tool like Postman or cURL to exchange code for token:
   ```bash
   curl -X POST https://oauth-provider.com/token \
     -d "grant_type=authorization_code" \
     -d "code=AUTH_CODE_FROM_STEP_3" \
     -d "client_id=your_client_id" \
     -d "client_secret=your_client_secret"
   ```
5. Use access token in subsequent API calls:
   ```bash
   curl -H "Authorization: Bearer ACCESS_TOKEN" https://api.example.com/user
   ```

**Testing Scenarios:**
- Valid authorization flow ‚úÖ
- Invalid client credentials ‚ùå  
- Expired authorization code ‚ùå
- Invalid access token ‚ùå
- Token refresh flow üîÑ

### 6. Session-Based Authentication

**What it is:** Server creates a session after login and gives the client a session ID.

**Analogy:** Like getting a hospital wristband - proves you're a patient and which room you belong to.

**How it works:**
1. User logs in with credentials
2. Server creates a session and returns session ID (usually in a cookie)
3. Client sends session ID with subsequent requests
4. Server validates session ID and processes request

**Manual Testing Sessions:**

**Using Postman:**
1. Create request for login endpoint:
   - Method: POST
   - URL: `https://api.example.com/login`  
   - Body: `{"username": "testuser", "password": "testpass"}`
2. Send login request and verify 200 status
3. Check response for Set-Cookie header or session token
4. For subsequent requests:
   - Postman automatically handles cookies
   - Or manually add session token to headers
5. Create profile request: `GET https://api.example.com/profile`
6. Verify 200 status (authenticated access)

**Browser Testing:**
1. Open browser developer tools ‚Üí Network tab
2. Navigate to login page and submit credentials
3. Monitor Set-Cookie headers in response
4. Navigate to protected pages and verify session cookies sent
5. Test session expiry:
   - Clear cookies in developer tools
   - Try accessing protected page ‚Üí Expect 401/redirect

**Session Testing Scenarios:**
- Valid login credentials ‚úÖ
- Invalid login credentials ‚ùå
- Session timeout/expiry ‚è∞
- Session hijacking prevention üîí
- Concurrent sessions üë•
- Session logout/cleanup üö™

**Using Browser Console:**
```javascript
// Login and establish session
fetch('https://api.example.com/login', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({username: 'testuser', password: 'testpass'}),
    credentials: 'include'  // Include cookies
})
.then(response => console.log('Login status:', response.status))

// Access protected resource
fetch('https://api.example.com/profile', {
    credentials: 'include'  // Send session cookies
})
.then(response => console.log('Profile access status:', response.status))
```

### Multi-Factor Authentication (MFA)

**What it is:** Additional security layer requiring multiple forms of verification.

**Common MFA Methods:**
- **SMS Code:** Text message with verification code
- **Email Code:** Email with verification code  
- **Authenticator App:** Google Authenticator, Authy
- **Biometric:** Fingerprint, face recognition

**Testing MFA:**

**Manual Testing Flow:**
1. **Initial Login:** Use Postman to send login credentials
   - Expected: 202 Accepted with MFA token
2. **MFA Challenge:** Submit verification code with MFA token
   - Expected: 200 OK with access token  
3. **Protected Access:** Use access token for subsequent requests
   - Expected: 200 OK with protected data

**Test Scenarios:**
- Valid MFA code: Should complete authentication
- Invalid MFA code: Should return 401 Unauthorized
- Expired MFA token: Should require restart of flow
- Missing MFA code: Should return 400 Bad Request

**Manual Testing Tools:**
- **Postman:** Create collection for multi-step MFA flow
- **Browser DevTools:** Monitor MFA requests in Network tab
- **Authenticator Apps:** Use for time-based OTP testing

### Authorization Concepts

### Authorization Concepts

**Role-Based Access Control (RBAC):**

**Manual Testing Approach:**
1. **Admin Role Testing:**
   - Use admin token in Postman Authorization header
   - Test access to admin endpoints (should return 200 OK)
   - Test user management operations (create, delete users)

2. **Regular User Testing:**
   - Use regular user token 
   - Test access to admin endpoints (should return 403 Forbidden)
   - Test access to own profile (should return 200 OK)

**Permission-Based Testing:**

**Manual Test Matrix:**
| Role | HTTP Method | Endpoint | Expected Status | Notes |
|------|-------------|----------|-----------------|-------|
| Admin | DELETE | /users/123 | 200 | Can delete any user |
| Moderator | DELETE | /users/123 | 403 | Cannot delete users |
| User | GET | /users/123 | 200 | Can view user profiles |
| User | PUT | /users/456 | 403 | Cannot edit other users |
| User | PUT | /users/123 | 200 | Can edit own profile |

**Testing Tools:**
- **Postman Collections:** Create different requests with role-based tokens
- **Environment Variables:** Store different user tokens for easy switching

### Authentication Testing Best Practices

**1. Test All Authentication Methods:**

**Manual Testing Matrix:**
| Endpoint | No Auth | Basic Auth | Bearer Token | API Key | Expected Result |
|----------|---------|------------|--------------|---------|------------------|
| /api/users | 401 | 200 | 200 | 200 | Public vs Protected |
| /api/orders | 401 | 200 | 200 | 200 | Protected resource |
| /api/admin | 401 | 403 | 200* | 403 | Admin-only access |

*Depends on token permissions

**Manual Testing Steps:**
1. **Test without authentication** - should return 401
2. **Test with Basic Auth** - encode username:password in Base64
3. **Test with Bearer tokens** - use JWT or API tokens
4. **Test with API keys** - use X-API-Key header or query parameter

**2. Test Token Lifecycle:**

**Manual Token Testing:**
1. **Token Generation:**
   - Use login endpoint to generate new token
   - Verify token format and expiration time
   - Check response includes refresh token if applicable

2. **Token Usage:**
   - Add token to Authorization header in Postman
   - Test protected endpoints return 200 OK
   - Verify token grants appropriate access

3. **Token Refresh:**
   - Use refresh token endpoint before expiration
   - Verify new token is different from old token
   - Test old token becomes invalid after refresh

4. **Token Revocation:**
   - Call logout or revoke endpoint
   - Test revoked token returns 401 Unauthorized
   - Verify token cannot be used for further requests

**3. Security Testing Scenarios:**

**Manual Security Testing:**
1. **Brute Force Protection:**
   - Make multiple failed login attempts (5-10 times)
   - Expected: Account lockout or rate limiting (429 status)
   - Test account unlock process

2. **SQL Injection Testing:**
   - Test login with malicious inputs:
     - `' OR '1'='1`
     - `admin'; DROP TABLE users; --`
     - `' UNION SELECT * FROM users --`
   - Expected: 400 Bad Request or 401 Unauthorized (never 200 OK)

3. **XSS in Authentication:**
   - Test with script tags in username/password fields
   - Verify API sanitizes input properly
   - Check error messages don't reflect malicious input

### 7. JSON (JavaScript Object Notation) - Comprehensive Format Guide

**Classification:** Data Format Standard

**What it is:** JSON is the most common data format for API communication. It's lightweight, human-readable, and language-independent.

**Why JSON for APIs:**
- **Simplicity:** Easy to read and write
- **Lightweight:** Less overhead than XML
- **Native JavaScript support:** Perfect for web applications
- **Wide language support:** Every programming language can parse JSON
- **Structure flexibility:** Supports complex nested data

**JSON Data Types:**
| Data Type | Description | Example |
|-----------|-------------|---------|
| `string` | Text wrapped in double quotes | `"Hello World"` |
| `number` | Integer or decimal | `42`, `3.14`, `-100` |
| `boolean` | true or false | `true`, `false` |
| `null` | Represents no value | `null` |
| `object` | Key-value pairs in curly braces | `{"name": "John"}` |
| `array` | Ordered list in square brackets | `[1, 2, 3]` |

**JSON Structure Examples:**

**1. Simple Object:**
```json
{
  "id": 123,
  "name": "John Doe",
  "email": "john@example.com",
  "active": true,
  "lastLogin": null
}
```

**2. Nested Objects:**
```json
{
  "user": {
    "id": 123,
    "personalInfo": {
      "firstName": "John",
      "lastName": "Doe",
      "address": {
        "street": "123 Main St",
        "city": "New York",
        "zipCode": "10001",
        "country": "USA"
      }
    },
    "preferences": {
      "theme": "dark",
      "notifications": true,
      "language": "en"
    }
  }
}
```

**3. Arrays and Mixed Data:**
```json
{
  "orders": [
    {
      "orderId": 1001,
      "items": [
        {"productId": 1, "name": "Laptop", "price": 999.99, "quantity": 1},
        {"productId": 2, "name": "Mouse", "price": 29.99, "quantity": 2}
      ],
      "total": 1059.97,
      "status": "shipped"
    },
    {
      "orderId": 1002,
      "items": [
        {"productId": 3, "name": "Keyboard", "price": 79.99, "quantity": 1}
      ],
      "total": 79.99,
      "status": "pending"
    }
  ],
  "totalOrders": 2,
  "pagination": {
    "currentPage": 1,
    "totalPages": 5,
    "hasNext": true
  }
}
```

**JSON Syntax Rules:**
- **Keys must be strings** in double quotes: `"name"`
- **Values can be:** string, number, boolean, null, object, array
- **No trailing commas:** Last item can't have comma
- **No comments:** JSON doesn't support comments
- **Case-sensitive:** `"Name"` and `"name"` are different

**Common JSON Patterns in APIs:**

**1. Success Response:**
```json
{
  "success": true,
  "data": {
    "userId": 123,
    "message": "User created successfully"
  },
  "timestamp": "2024-01-15T10:30:00Z"
}
```

**2. Error Response:**
```json
{
  "success": false,
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid input data",
    "details": [
      {
        "field": "email",
        "message": "Invalid email format"
      },
      {
        "field": "age",
        "message": "Age must be between 18 and 100"
      }
    ]
  },
  "timestamp": "2024-01-15T10:30:00Z"
}
```

**3. Paginated List Response:**
```json
{
  "data": [
    {"id": 1, "name": "User 1"},
    {"id": 2, "name": "User 2"}
  ],
  "pagination": {
    "page": 1,
    "pageSize": 10,
    "totalItems": 150,
    "totalPages": 15,
    "hasNext": true,
    "hasPrevious": false
  },
  "links": {
    "self": "/api/users?page=1",
    "next": "/api/users?page=2",
    "last": "/api/users?page=15"
  }
}
```

**Manual JSON Testing Techniques:**

**1. Browser Developer Tools JSON Validation:**
```javascript
// In Console tab, validate JSON format
try {
  const jsonData = JSON.parse('{"name": "John", "age": 30}');
  console.log('Valid JSON:', jsonData);
} catch (error) {
  console.error('Invalid JSON:', error.message);
}

// Pretty print JSON for readability
const uglyJson = '{"name":"John","age":30,"address":{"city":"NYC"}}';
console.log(JSON.stringify(JSON.parse(uglyJson), null, 2));
```

**2. JSON Format Validation Checklist:**
- ‚úÖ All strings use double quotes (not single quotes)
- ‚úÖ No trailing commas after last array/object element
- ‚úÖ All brackets and braces are properly closed
- ‚úÖ Special characters are properly escaped
- ‚úÖ Numbers don't have leading zeros (except for decimals)
- ‚úÖ Boolean values are lowercase (`true`/`false`)
- ‚úÖ Null values use lowercase `null`

**3. Common JSON Validation Errors:**

**Invalid JSON Examples:**
```json
// ‚ùå Single quotes instead of double quotes
{'name': 'John'}

// ‚ùå Trailing comma
{"name": "John", "age": 30,}

// ‚ùå Unescaped quotes in string
{"message": "He said "Hello""}

// ‚ùå Leading zeros
{"number": 0123}

// ‚ùå Undefined instead of null
{"value": undefined}
```

**Valid JSON Corrections:**
```json
// ‚úÖ Correct format
{"name": "John"}

// ‚úÖ No trailing comma
{"name": "John", "age": 30}

// ‚úÖ Escaped quotes
{"message": "He said \"Hello\""}

// ‚úÖ No leading zeros
{"number": 123}

// ‚úÖ Use null instead of undefined
{"value": null}
```

**4. JSON Schema Validation in Manual Testing:**

**Sample JSON Schema:**
```json
{
  "type": "object",
  "properties": {
    "name": {"type": "string", "minLength": 1},
    "age": {"type": "integer", "minimum": 0, "maximum": 150},
    "email": {"type": "string", "format": "email"},
    "active": {"type": "boolean"}
  },
  "required": ["name", "email"]
}
```

**Manual Schema Testing Scenarios:**
- **Test 1:** Valid data matches schema perfectly
- **Test 2:** Missing required fields (should fail)
- **Test 3:** Invalid data types (string instead of number)
- **Test 4:** Values outside allowed ranges
- **Test 5:** Invalid email format
- **Test 6:** Extra fields (depending on schema settings)

**5. Browser Tools for JSON Testing:**

**Network Tab JSON Analysis:**
1. Open Network tab in Developer Tools
2. Filter by XHR/Fetch to see API calls
3. Click on response to view JSON
4. Use Preview tab for formatted view
5. Use Response tab for raw JSON

**Console Tab JSON Testing:**
```javascript
// Test JSON parsing
fetch('/api/users/1')
  .then(response => response.json())
  .then(data => {
    console.log('Response structure:', Object.keys(data));
    console.log('Data types:', typeof data.name, typeof data.age);
    console.log('Full data:', JSON.stringify(data, null, 2));
  })
  .catch(error => console.error('JSON parsing error:', error));
```

**Manual Testing Best Practices for JSON:**
1. **Always validate JSON syntax** before testing business logic
2. **Check data types** match API documentation
3. **Verify required fields** are present and non-null
4. **Test with edge cases** (empty strings, very large numbers)
5. **Validate nested structures** for completeness
6. **Check array handling** (empty arrays, single items, large lists)
7. **Test special characters** in string values
8. **Verify date/time formats** follow standards (ISO 8601)

---

## Getting Started - Your First API Test

### Prerequisites
- Basic understanding of HTTP
- Knowledge of JSON format
- Any API testing tool (we'll start with Postman)

### Your First API Call

Let's test a simple public API - JSONPlaceholder:

**1. Test GET Request**
```http
GET https://jsonplaceholder.typicode.com/posts/1
```

**Expected Response:**
```json
{
  "userId": 1,
  "id": 1,
  "title": "sunt aut facere repellat provident occaecati excepturi optio reprehenderit",
  "body": "quia et suscipit..."
}
```

**What to Validate:**
- Status Code: 200
- Response time: < 2 seconds
- Response contains required fields
- Data types are correct

**2. Test POST Request**
```http
POST https://jsonplaceholder.typicode.com/posts
Content-Type: application/json

{
  "title": "My Test Post",
  "body": "This is test content",
  "userId": 1
}
```

**Expected Response:**
```json
{
  "id": 101,
  "title": "My Test Post",
  "body": "This is test content",
  "userId": 1
}
```

### Quick Exercise
Try these scenarios:
1. Get user details: `GET /users/1`
2. Get all posts: `GET /posts`
3. Create a new user: `POST /users`
4. Update a post: `PUT /posts/1`
5. Delete a post: `DELETE /posts/1`

---

## üèóÔ∏è Microservices & Modern Architecture

### What are Microservices?

**Simple Definition:** Microservices are like a team of specialists instead of one person doing everything. Instead of having one large application (monolith), you break it down into small, independent services that work together.

**Traditional Monolith vs Microservices:**
```
MONOLITH (One Big Application):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User UI ‚îÇ Orders ‚îÇ Payment ‚îÇ   ‚îÇ
‚îÇ  Login   ‚îÇ Cart   ‚îÇ Billing ‚îÇ   ‚îÇ
‚îÇ  Profile ‚îÇ Items  ‚îÇ Shipping‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        One Database

MICROSERVICES (Multiple Small Services):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User   ‚îÇ  ‚îÇ  Order   ‚îÇ  ‚îÇ Payment  ‚îÇ
‚îÇ Service  ‚îÇ  ‚îÇ Service  ‚îÇ  ‚îÇ Service  ‚îÇ
‚îÇ    DB    ‚îÇ  ‚îÇ    DB    ‚îÇ  ‚îÇ    DB    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Benefits for Testing:**
- **Independent Testing:** Test each service separately
- **Faster Feedback:** Smaller services = faster tests
- **Isolation:** Problems in one service don't break others
- **Technology Diversity:** Different services can use different tech stacks

### Popular Microservices Technologies

**1. Containerization:**
- **Docker:** Package applications with their dependencies
  - **For Testing:** Create consistent test environments
  - **Example:** Run API tests in Docker containers
- **Docker Compose:** Manage multiple containers
  - **For Testing:** Spin up entire microservices stack for testing

**2. Orchestration:**
- **Kubernetes (K8s):** Manage containers at scale
  - **For Testing:** Deploy test environments quickly
  - **Features:** Auto-scaling, load balancing, health checks
- **Docker Swarm:** Simpler container orchestration
  - **For Testing:** Lighter alternative to Kubernetes

**3. Service Mesh:**
- **Istio:** Connect, secure, control microservices
  - **For Testing:** Test service-to-service communication
  - **Features:** Traffic management, security policies, observability
- **Linkerd:** Lightweight service mesh
  - **For Testing:** Monitor request routing and failures

**4. Message Queues & Event Streaming:**
- **Apache Kafka:** High-throughput event streaming
  - **For Testing:** Test event-driven workflows
  - **Use Cases:** Real-time data processing, event sourcing
- **RabbitMQ:** Reliable message broker
  - **For Testing:** Test asynchronous communication
  - **Use Cases:** Task queues, pub/sub messaging
- **Amazon SQS/SNS:** Cloud-based messaging
  - **For Testing:** Test cloud-native communication patterns

**5. API Gateways:**
- **Kong:** Cloud-native API gateway
  - **For Testing:** Test API routing, rate limiting, authentication
- **AWS API Gateway:** Managed API service
  - **For Testing:** Test serverless API workflows
- **Nginx:** High-performance web server and reverse proxy
  - **For Testing:** Test load balancing and caching
- **Envoy Proxy:** High-performance proxy for modern architectures
  - **For Testing:** Test advanced routing and observability

**6. Service Discovery:**
- **Consul:** Service networking solution
  - **For Testing:** Test dynamic service discovery
- **Eureka:** Service registry for resilient mid-tier load balancing
  - **For Testing:** Test service registration and discovery

**7. Monitoring & Observability:**
- **Prometheus:** Monitoring and alerting toolkit
  - **For Testing:** Monitor API performance metrics
- **Grafana:** Data visualization and monitoring
  - **For Testing:** Create dashboards for test results
- **Jaeger:** Distributed tracing system
  - **For Testing:** Trace requests across microservices
- **ELK Stack (Elasticsearch, Logstash, Kibana):** Search and analytics
  - **For Testing:** Analyze test logs and results

### Microservices Testing Strategies

**1. Testing Pyramid for Microservices:**
```
           /\
          /E2E\     ‚Üê Few end-to-end tests (full user journeys)
         /____\
        /      \
       /Contract\   ‚Üê Contract tests (service boundaries)
      /________\
     /          \
    / Integration\ ‚Üê Integration tests (service interactions)
   /__________\
  /            \
 / Unit + API   \ ‚Üê Many unit and individual API tests
/________________\
```

**2. Contract Testing:**
- **Purpose:** Ensure services can communicate correctly
- **Tools:** Pact, Spring Cloud Contract
- **What to Test:** API contracts between services

**3. Service-Level Testing:**
- **Purpose:** Test individual microservices in isolation
- **Approach:** Mock external dependencies
- **What to Test:** Business logic, data validation, error handling

**4. Integration Testing:**
- **Purpose:** Test service interactions
- **Approach:** Test with real dependencies or test doubles
- **What to Test:** Data flow, communication patterns, fallback mechanisms

**5. End-to-End Testing:**
- **Purpose:** Test complete user workflows
- **Approach:** Test through user interfaces or API orchestration
- **What to Test:** Critical business paths, cross-service workflows

### Common Microservices Patterns to Test

**1. Circuit Breaker Pattern:**
- **Purpose:** Prevent cascading failures
- **Testing:** Verify fallback behavior when services are down
- **Tools:** Hystrix, Resilience4j

**2. API Gateway Pattern:**
- **Purpose:** Single entry point for clients
- **Testing:** Test routing, authentication, rate limiting
- **Examples:** Kong, Zuul, AWS API Gateway

**3. Saga Pattern:**
- **Purpose:** Manage distributed transactions
- **Testing:** Test compensation logic for failed transactions
- **Types:** Orchestration vs Choreography

**4. Event Sourcing:**
- **Purpose:** Store state changes as events
- **Testing:** Test event replay, consistency, ordering

**5. CQRS (Command Query Responsibility Segregation):**
- **Purpose:** Separate read and write operations
- **Testing:** Test command and query sides independently

### Manual Testing Approaches for Microservices

**1. Postman for Microservices Testing:**
```javascript
// Environment variables for different services
pm.environment.set("userServiceUrl", "http://user-service:8080");
pm.environment.set("orderServiceUrl", "http://order-service:8080");
pm.environment.set("paymentServiceUrl", "http://payment-service:8080");

// Test workflow across services
pm.test("Complete order workflow", function() {
    // 1. Create user
    // 2. Add items to cart  
    // 3. Process payment
    // 4. Create order
    // 5. Verify order status
});
```

**2. Browser Developer Tools for Microservices:**
- **Network Tab:** Track calls to different services
- **Look for:** Service URLs, request/response patterns
- **Monitor:** Cross-service communication timings

**3. Docker Compose for Local Testing:**
```yaml
version: '3.8'
services:
  user-service:
    image: user-service:latest
    ports:
      - "8081:8080"
  
  order-service:
    image: order-service:latest
    ports:
      - "8082:8080"
    depends_on:
      - user-service
  
  payment-service:
    image: payment-service:latest
    ports:
      - "8083:8080"
```

### Testing Challenges in Microservices

**1. Service Dependencies:**
- **Challenge:** Services depend on other services
- **Solution:** Use service virtualization, mocking, or contract testing

**2. Data Consistency:**
- **Challenge:** Data spread across multiple databases
- **Solution:** Test eventual consistency, event ordering

**3. Network Failures:**
- **Challenge:** Services communicate over network
- **Solution:** Test timeouts, retries, circuit breakers

**4. Service Discovery:**
- **Challenge:** Services need to find each other
- **Solution:** Test service registration and discovery mechanisms

**5. Distributed Tracing:**
- **Challenge:** Tracking requests across services
- **Solution:** Use correlation IDs, distributed tracing tools

### Real-World Example: E-commerce Microservices

**Services:**
- **User Service:** Manages user profiles and authentication
- **Product Service:** Manages product catalog
- **Order Service:** Handles order processing
- **Payment Service:** Processes payments
- **Notification Service:** Sends emails/SMS
- **Inventory Service:** Manages stock levels

**Testing Workflow:**
1. **User Registration:** Test user service independently
2. **Product Search:** Test product service with search functionality
3. **Add to Cart:** Test session management and product availability
4. **Checkout Process:** Test orchestration across multiple services
5. **Payment Processing:** Test payment service integration
6. **Order Confirmation:** Test notification service triggers
7. **Inventory Update:** Test eventual consistency across services

---

## API Testing Types

### 1. Functional Testing

**Purpose:** Verifies that API functions work as expected

**Test Scenarios:**
- **Endpoint Availability:** Verify endpoints are accessible
- **Request Validation:** Test with valid/invalid requests
- **Response Validation:** Verify response structure and data
- **Error Handling:** Test error scenarios
- **Business Logic:** Validate business rules

**Manual Test Examples:**

**User Creation Testing (Postman):**
1. **Valid User Creation:**
   - Method: POST
   - URL: `/api/users`
   - Body (JSON):
   ```json
   {
     "name": "John Doe",
     "email": "john@example.com", 
     "age": 30
   }
   ```
   - Expected: 201 status, response contains user ID and submitted data

2. **Invalid Email Testing:**
   - Method: POST  
   - URL: `/api/users`
   - Body (JSON):
   ```json
   {
     "name": "John Doe",
     "email": "invalid-email",
     "age": 30
   }
   ```
   - Expected: 400 status, error message about invalid email format

**Browser Console Testing:**
```javascript
// Test valid user creation
fetch('/api/users', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        name: "John Doe",
        email: "john@example.com",
        age: 30
    })
})
.then(response => {
    console.log('Status:', response.status);
    return response.json();
})
.then(data => console.log('Response:', data));

// Test invalid email
fetch('/api/users', {
    method: 'POST', 
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        name: "John Doe",
        email: "invalid-email",
        age: 30
    })
})
.then(response => {
    console.log('Status:', response.status);
    return response.json();
})
.then(data => console.log('Error response:', data));
```

### 2. Integration Testing

**Purpose:** Tests interaction between different API components

**Types:**
- **API to API:** Testing communication between microservices
- **API to Database:** Verify data persistence
- **API to External Services:** Test third-party integrations

**Manual Integration Testing Example:**

**Order Processing Flow (Postman Collection):**
1. **Create User Request:**
   - Method: POST
   - URL: `/api/users`
   - Body: User data JSON
   - Save user ID from response

2. **Add to Cart Request:**
   - Method: POST  
   - URL: `/api/users/{{user_id}}/cart`
   - Body: `{"product_id": 1, "quantity": 2}`
   - Use user_id variable from step 1

3. **Process Payment Request:**
   - Method: POST
   - URL: `/api/payments`  
   - Body: `{"user_id": "{{user_id}}", "amount": 50.00}`
   - Save payment ID from response

4. **Create Order Request:**
   - Method: POST
   - URL: `/api/orders`
   - Body: `{"user_id": "{{user_id}}", "payment_id": "{{payment_id}}"}`
   - Verify: 201 status, order status = "confirmed"

**Manual Testing Checklist:**
- ‚úÖ Each step returns expected status code
- ‚úÖ Data flows correctly between steps  
- ‚úÖ Final order contains correct user and payment info
- ‚úÖ Error handling if any step fails
- ‚úÖ Database consistency checks

### 3. Contract Testing

**Purpose:** Ensures API producer and consumer agree on interface

**Tools:** Pact, Spring Cloud Contract

**Manual Contract Testing Approach:**

**API Documentation Review:**
1. **Review API Specification:**
   - OpenAPI/Swagger documentation
   - Request/response schemas
   - Required vs optional fields
   - Data types and formats

2. **Manual Contract Validation:**
   - Create test requests matching exact specification
   - Verify response structure matches documented schema
   - Test with Postman schema validation:
     ```javascript
     // In Postman Tests tab
     pm.test("Response matches schema", function () {
         const schema = {
             type: "object",
             properties: {
                 id: { type: "number" },
                 name: { type: "string" },
                 permissions: { 
                     type: "array",
                     items: { type: "string" }
                 }
             },
             required: ["id", "name", "permissions"]
         };
         pm.response.to.have.jsonSchema(schema);
     });
     ```

3. **Cross-team Validation:**
   - Share API examples with consuming teams
   - Validate assumptions about data formats
   - Document breaking changes and versioning strategy

**Manual Testing Steps:**
- ‚úÖ Request format matches specification
- ‚úÖ Response structure is consistent  
- ‚úÖ Error responses follow documented patterns
- ‚úÖ Authentication requirements are clear
- ‚úÖ Rate limiting behavior is documented

### 4. Performance Testing

**Purpose:** Evaluate API performance under various load conditions

**Key Metrics:** Response time, throughput, concurrent users, error rate

**Test Types:** Load, stress, spike, volume, and endurance testing

> üìñ **See comprehensive coverage in [üìä Performance & Load Testing](#-performance--load-testing) section for detailed techniques, tools, and examples.**

### 5. Security Testing

**Purpose:** Identify vulnerabilities and security flaws

**Common Security Tests:**
- **Authentication Testing:** Verify authentication mechanisms
- **Authorization Testing:** Test access controls
- **Input Validation:** SQL injection, XSS prevention
- **Data Encryption:** Verify sensitive data protection
- **Rate Limiting:** Test API abuse protection

**Manual Security Testing Examples:**

**1. Unauthorized Access Testing (Postman):**
- Create request to protected endpoint: `GET /api/admin/users`
- Remove all authentication headers
- Send request and verify 401 Unauthorized status
- Test with expired/invalid tokens ‚Üí Expect 401/403

**2. SQL Injection Testing:**
- **Test Payload:** Send malicious input in request body:
  ```json
  {"name": "'; DROP TABLE users; --"}
  ```
- **Expected Result:** 400 Bad Request (input validation)
- **Verification:** Make normal request to verify system integrity
- **Browser Console Test:**
  ```javascript
  fetch('/api/users', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({name: "'; DROP TABLE users; --"})
  })
  .then(response => console.log('Injection test status:', response.status))
  
  // Verify system still works
  fetch('/api/users')
  .then(response => console.log('System integrity check:', response.status))
  ```

**3. XSS Testing:**
- Test script injection in form fields:
  ```json
  {"name": "<script>alert('XSS')</script>"}
  ```
- Verify proper encoding/sanitization in responses

**4. Rate Limiting Testing:**
- Send multiple rapid requests to same endpoint
- Monitor for 429 Too Many Requests status
- Test different rate limit scenarios (per user, per IP, per endpoint)

**Manual Rate Limiting Testing:**

**Postman Collection Runner:**
1. Create a simple GET request to `/api/users`
2. Use Collection Runner with:
   - Iterations: 110
   - Delay: 0ms (to exceed rate limits quickly)
3. Monitor responses:
   - First 100 requests: 200 OK
   - Requests 101+: 429 Too Many Requests

**Browser Console Rapid Testing:**
```javascript
// Send rapid requests to test rate limiting
async function testRateLimit() {
    const results = [];
    for (let i = 0; i < 110; i++) {
        try {
            const response = await fetch('/api/users');
            results.push({request: i+1, status: response.status});
            if (response.status === 429) {
                console.log(`Rate limit hit at request ${i+1}`);
                break;
            }
        } catch (error) {
            console.log(`Error at request ${i+1}:`, error);
        }
    }
    return results;
}

testRateLimit().then(results => console.table(results));
```
```

---

## üß™ API Testing Fundamentals

### What is API Testing?

**Simple Definition:** API testing is like testing the kitchen of a restaurant. You're not testing how the dining room looks (that's UI testing), but whether the kitchen can:
- Take orders correctly
- Prepare food as requested  
- Send out the right dishes
- Handle multiple orders at once
- Work when ingredients are missing

**Technical Definition:** API testing is a type of software testing that involves testing Application Programming Interfaces (APIs) directly and as part of integration testing to determine if they meet expectations for functionality, reliability, performance, and security.

### Why is API Testing Important?

**1. Early Bug Detection**
- Find issues before UI development
- Cheaper to fix bugs at the API level
- Faster feedback cycle

**2. Better Test Coverage**
- Test business logic directly
- Access all application features
- Test edge cases easier

**3. Faster Execution**
- No UI rendering delays
- Lighter weight tests
- Better for CI/CD pipelines

**4. Platform Independent**
- Same API serves web, mobile, IoT
- Test once, benefit everywhere
- Consistent behavior validation

### Types of API Testing

**1. Functional Testing**
- **What it tests:** Does the API do what it's supposed to do?
- **Example:** When I send a GET request for user ID 123, do I get back user 123's data?

**Manual Functional Testing Example:**

**Testing User Retrieval (Postman):**
1. Create GET request to `https://api.example.com/users/123`
2. Send request and verify:
   - Status code: 200 OK
   - Response contains user ID 123
   - Response has required fields: name, email
   - Email format validation (contains @)

**Browser Console Testing:**
```javascript
fetch('https://api.example.com/users/123')
.then(response => {
    console.log('Status:', response.status);
    return response.json();
})
.then(user => {
    console.log('User ID:', user.id);
    console.log('Has name:', 'name' in user);
    console.log('Has email:', 'email' in user);
    console.log('Email format valid:', user.email.includes('@'));
});
```

**2. Data-Driven Testing**
- **What it tests:** API behavior with different data sets
- **Example:** Test user creation with various input combinations

**Manual Data-Driven Testing:**

**Testing User Creation with Various Data (Postman Collection):**

Create multiple requests in Postman collection:

1. **Valid User Creation:**
   - POST `https://api.example.com/users`
   - Body: `{"name": "John Doe", "email": "john@example.com"}`
   - Expected: 201 Created

2. **Missing Name Test:**
   - POST `https://api.example.com/users`
   - Body: `{"name": "", "email": "john@example.com"}`
   - Expected: 400 Bad Request

3. **Invalid Email Test:**
   - POST `https://api.example.com/users`
   - Body: `{"name": "John Doe", "email": "invalid-email"}`
   - Expected: 400 Bad Request

4. **Missing Email Test:**
   - POST `https://api.example.com/users`
   - Body: `{"name": "John Doe", "email": ""}`
   - Expected: 400 Bad Request

5. **Name Too Long Test:**
   - POST `https://api.example.com/users`
   - Body: `{"name": "A".repeat(256), "email": "john@example.com"}`
   - Expected: 400 Bad Request

**Browser Console Batch Testing:**
```javascript
const testCases = [
    {name: "John Doe", email: "john@example.com", expected: 201},
    {name: "", email: "john@example.com", expected: 400},
    {name: "John Doe", email: "invalid-email", expected: 400},
    {name: "John Doe", email: "", expected: 400},
    {name: "A".repeat(256), email: "john@example.com", expected: 400}
];

testCases.forEach((testCase, index) => {
    fetch('https://api.example.com/users', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({name: testCase.name, email: testCase.email})
    })
    .then(response => {
        console.log(`Test ${index + 1}: Expected ${testCase.expected}, Got ${response.status}`);
    });
});
```

**3. Integration Testing**
- **What it tests:** How APIs work together
- **Example:** Create user ‚Üí Create order ‚Üí Update order ‚Üí Get order history

**Manual Integration Testing Flow:**

**User Order Flow (Postman Collection):**

1. **Create User:**
   - POST `https://api.example.com/users`
   - Body: `{"name": "Test User", "email": "test@example.com"}`
   - Save user_id from response for next steps

2. **Create Order:**
   - POST `https://api.example.com/orders`
   - Body: `{"user_id": "{{user_id}}", "product": "laptop", "quantity": 1}`
   - Save order_id from response

3. **Update Order:**
   - PUT `https://api.example.com/orders/{{order_id}}`
   - Body: `{"status": "shipped"}`
   - Verify 200 status

4. **Get Order History:**
   - GET `https://api.example.com/users/{{user_id}}/orders`
   - Verify response contains 1 order with status "shipped"

**Browser Console Integration Test:**
```javascript
async function testUserOrderFlow() {
    try {
        // Step 1: Create user
        const userResponse = await fetch('https://api.example.com/users', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({name: "Test User", email: "test@example.com"})
        });
        const user = await userResponse.json();
        console.log('User created:', user.id);
        
        // Step 2: Create order
        const orderResponse = await fetch('https://api.example.com/orders', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({user_id: user.id, product: "laptop", quantity: 1})
        });
        const order = await orderResponse.json();
        console.log('Order created:', order.id);
        
        // Step 3: Update order
        const updateResponse = await fetch(`https://api.example.com/orders/${order.id}`, {
            method: 'PUT',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({status: "shipped"})
        });
        console.log('Order updated:', updateResponse.status);
        
        // Step 4: Get order history
        const historyResponse = await fetch(`https://api.example.com/users/${user.id}/orders`);
        const orders = await historyResponse.json();
        console.log('Order history:', orders);
        console.log('Test passed:', orders.length === 1 && orders[0].status === 'shipped');
        
    } catch (error) {
        console.error('Integration test failed:', error);
    }
}

testUserOrderFlow();
```

**4. Load Testing**
- **What it tests:** API performance under normal and peak loads
- **Example:** Can the API handle 100 concurrent users?

**Manual Load Testing Approaches:**

**Using Postman Collection Runner:**
1. Create a simple GET request to `https://api.example.com/users`
2. Use Collection Runner with:
   - Iterations: 100
   - Delay: 0ms (for concurrent simulation)
   - Data file: Optional for varied test data
3. Monitor results:
   - Response times for each request
   - Success rate percentage  
   - Identify performance bottlenecks

**Browser-Based Load Simulation:**
```javascript
async function loadTest() {
    const startTime = Date.now();
    const promises = [];
    
    // Create 50 concurrent requests
    for (let i = 0; i < 50; i++) {
        promises.push(
            fetch('https://api.example.com/users')
            .then(response => ({
                status: response.status,
                responseTime: Date.now() - startTime
            }))
        );
    }
    
    const results = await Promise.all(promises);
    const successCount = results.filter(r => r.status === 200).length;
    const avgResponseTime = results.reduce((sum, r) => sum + r.responseTime, 0) / results.length;
    
    console.log(`Success rate: ${(successCount/50)*100}%`);
    console.log(`Average response time: ${avgResponseTime}ms`);
    
    return { successRate: successCount/50, avgResponseTime };
}

loadTest();
```

**Load Testing Checklist:**
- ‚úÖ 95%+ success rate under normal load
- ‚úÖ Response times under 2 seconds
- ‚úÖ No memory leaks or crashes
- ‚úÖ Graceful degradation under peak load

**5. Security Testing**
- **What it tests:** API vulnerabilities and security measures
- **Example:** Authentication, authorization, data validation

**Manual Security Testing Examples:**

**1. Authentication Testing (Postman):**
- Send request to `GET https://api.example.com/admin/users` without auth headers
- Expected: 401 Unauthorized
- Test with expired/invalid tokens

**2. SQL Injection Testing:**
- Send malicious input in query parameters:
  `GET https://api.example.com/users?name='; DROP TABLE users; --`
- Expected: 400/422 status (proper input validation)
- Verify system integrity with follow-up normal request

**3. Cross-Site Scripting (XSS) Testing:**
- POST request with XSS payload:
  ```json
  {"name": "<script>alert('xss')</script>"}
  ```
- Expected: 400/422 status (input sanitization)
- Check response doesn't echo raw script content

**4. Rate Limiting Testing:**
- Send rapid requests to same endpoint  
- Monitor for 429 Too Many Requests status
- Test different scenarios (per user, per IP)

**Browser Console Security Tests:**
```javascript
// Test unauthorized access
fetch('https://api.example.com/admin/users')
.then(response => console.log('Unauthorized access status:', response.status));

// Test SQL injection
fetch('https://api.example.com/users?name=' + encodeURIComponent("'; DROP TABLE users; --"))
.then(response => console.log('SQL injection test status:', response.status));

// Test XSS
fetch('https://api.example.com/users', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({name: "<script>alert('xss')</script>"})
})
.then(response => console.log('XSS test status:', response.status));
```

**Security Testing Checklist:**
- ‚úÖ Unauthorized access blocked (401/403)
- ‚úÖ SQL injection attempts rejected
- ‚úÖ XSS payloads sanitized  
- ‚úÖ Rate limiting enforced
- ‚úÖ Sensitive data not exposed in errors

### API Testing Process

**1. Understand the API**
- Read API documentation
- Understand endpoints and methods
- Learn about authentication requirements
- Study data models and relationships

**2. Plan Test Cases**

**Manual Test Planning Checklist:**

**Functional Tests:**
- ‚úÖ Valid input data scenarios
- ‚úÖ Invalid input data validation
- ‚úÖ Missing required fields handling
- ‚úÖ Extra fields in request behavior
- ‚úÖ Boundary value testing
- ‚úÖ Data type validation

**Authentication Tests:**
- ‚úÖ Valid credentials acceptance
- ‚úÖ Invalid credentials rejection
- ‚úÖ Expired tokens handling
- ‚úÖ Missing authentication response
- ‚úÖ Token refresh scenarios

**Business Logic Tests:**
- ‚úÖ Workflow testing end-to-end
- ‚úÖ Data consistency verification
- ‚úÖ State transitions validation
- ‚úÖ Business rule enforcement

**Error Handling Tests:**
- ‚úÖ 4xx client error responses
- ‚úÖ 5xx server error handling
- ‚úÖ Network timeout scenarios
- ‚úÖ Invalid response format handling
- ‚úÖ Graceful degradation testing

**3. Set Up Test Environment**

**Manual Test Environment Setup:**

**Environment Configuration:**
- Base URL: `https://api-staging.example.com`
- Timeout: 30 seconds for requests
- Authentication: Test API key or token
- Test data preparation

**Postman Environment Variables:**
```json
{
  "base_url": "https://api-staging.example.com",
  "auth_token": "test_token_here",
  "timeout": "30000"
}
```

**Test Data Collection:**
```json
{
  "valid_user": {
    "name": "Test User",
    "email": "testuser@example.com", 
    "age": 25
  },
  "invalid_user": {
    "name": "",
    "email": "invalid-email",
    "age": -5
  }
}
```

**4. Manual CRUD Testing Process**

**CRUD Operations Testing (Postman Collection):**

**Setup:** 
- Environment: `{{base_url}}` = `https://api-staging.example.com`
- Authorization: Bearer token `{{auth_token}}`

**Test Sequence:**

1. **CREATE User:**
   - Method: POST
   - URL: `{{base_url}}/users`
   - Body: `{{valid_user}}` data
   - Expected: 201 Created
   - **Save user_id from response for next steps**

2. **READ User:**
   - Method: GET  
   - URL: `{{base_url}}/users/{{user_id}}`
   - Expected: 200 OK with user data

3. **UPDATE User:**
   - Method: PUT
   - URL: `{{base_url}}/users/{{user_id}}`
   - Body: `{"name": "Updated Name"}`
   - Expected: 200 OK

4. **DELETE User:**
   - Method: DELETE
   - URL: `{{base_url}}/users/{{user_id}}`
   - Expected: 204 No Content

**Manual Verification Checklist:**
- ‚úÖ Each operation returns correct status code
- ‚úÖ CREATE returns user with ID
- ‚úÖ READ returns correct user data  
- ‚úÖ UPDATE modifies data correctly
- ‚úÖ DELETE removes user (verify with GET ‚Üí 404)

**5. Execute and Monitor Tests**

**Manual Test Execution Process:**

**Using Postman Collection Runner:**
1. **Create Collection:** Organize related tests into logical collections
2. **Set Environment:** Configure variables (base_url, auth_token, etc.)
3. **Run Collection:** Use Collection Runner for batch execution
4. **Monitor Results:**
   - Pass/fail rates
   - Response times
   - Error patterns
   - Data validation results

**Test Monitoring Checklist:**
- ‚úÖ Track response times for performance trends
- ‚úÖ Monitor error rates and patterns  
- ‚úÖ Validate data consistency across tests
- ‚úÖ Check authentication/authorization
- ‚úÖ Verify business logic correctness

**Manual Test Documentation:**
```markdown
# Test Execution Report
- **Test Suite:** User Management API
- **Environment:** Staging  
- **Date:** [Current Date]
- **Total Tests:** 25
- **Passed:** 23
- **Failed:** 2
- **Average Response Time:** 250ms

## Failed Tests:
1. User Creation with Invalid Email - 400 expected, got 500
2. Rate Limiting Test - 429 not returned after 100 requests
```
            else:
                test_results["failed"] += 1
                test_results["errors"].append(result.error)
                
        except Exception as e:
            test_results["failed"] += 1
            test_results["errors"].append(str(e))
    
    return test_results
```

### API Testing Best Practices

**1. Test Independence**

**‚ùå Poor Practice: Dependent Test Cases**
*Manual Test Case 1: Create User*
- Execute POST /users endpoint
- Save user ID from response for next test
- **Problem:** Next test depends on this test's success

*Manual Test Case 2: Get User (Dependent)*
- Use user ID from previous test
- Execute GET /users/{id} endpoint
- **Problem:** Fails if previous test failed

**‚úÖ Best Practice: Independent Test Cases**
*Manual Test Case 1: Create User (Independent)*
- Execute POST /users with valid data
- Verify 201 status code
- Verify response structure
- Clean up: Delete created user

*Manual Test Case 2: Get User (Independent)*
- Prerequisite: Create a test user first
- Execute GET /users/{id} endpoint
- Verify 200 status code and user data
- Clean up: Delete test user

**2. Comprehensive Verification**

**Manual Testing Verification Checklist:**

**Status Code Verification:**
- ‚úÖ Verify correct HTTP status code (200, 201, 400, 404, etc.)
- ‚úÖ Document expected vs actual status codes
- ‚úÖ Test edge cases (unauthorized, forbidden, etc.)

**Response Time Verification:**
- ‚úÖ Measure response time manually using browser dev tools
- ‚úÖ Document if response time exceeds 2 seconds
- ‚úÖ Test under different network conditions

**Content Type Verification:**
- ‚úÖ Verify 'Content-Type' header (application/json, text/html, etc.)
- ‚úÖ Check response format matches expected type
- ‚úÖ Validate charset encoding if applicable

**Response Body Structure Verification:**
- ‚úÖ Verify all required fields are present
- ‚úÖ Check data types (string, number, boolean, array)
- ‚úÖ Validate field values match input data
- ‚úÖ Confirm nested object structures
    assert user_data['email'] == payload['email']
    assert user_data['age'] == payload['age']
    
    # Business logic assertions- ‚úÖ Verify ID field exists and is positive number
- ‚úÖ Validate email format contains '@' symbol  
- ‚úÖ Check age meets business requirements (‚â•18)
- ‚úÖ Confirm all input data reflected in response

**3. Error Testing**

**Manual Error Testing Scenarios:**

**Test Case 1: Missing Required Fields**
- *Input:* Send empty JSON body `{}`
- *Expected:* 400 status code
- *Verify:* Error message mentions "Missing required fields"

**Test Case 2: Empty Name Field**
- *Input:* `{"name": ""}`
- *Expected:* 400 status code  
- *Verify:* Error message states "Name cannot be empty"

**Test Case 3: Invalid Email Format**
- *Input:* `{"name": "John", "email": "invalid"}`
- *Expected:* 400 status code
- *Verify:* Error message indicates "Invalid email format"

**Test Case 4: Negative Age Value**
- *Input:* `{"name": "John", "email": "john@example.com", "age": -1}`
- *Expected:* 400 status code
- *Verify:* Error message states "Age must be positive"

**Test Case 5: Name Length Validation**
- *Input:* `{"name": "A very long name exceeding maximum allowed length..."}`
- *Expected:* 400 status code
- *Verify:* Error message mentions "Name too long"

**Error Testing Verification Steps:**
1. Send each test case via Postman/curl
2. Record actual status code received
3. Copy and analyze error response body
4. Compare error message with expected text
5. Document any discrepancies

**4. Data Cleanup**

**Manual Data Cleanup Strategy:**
    def setUp(self):
        self.created_users = []
    
    def tearDown(self):
        # Clean up created test data
        for user_id in self.created_users:**Test Data Management:**
- Keep track of all test users created during testing
- Record user IDs in a test log or spreadsheet
- Clean up test data after each test session
- Use clearly identifiable test data (e.g., names starting with "TEST_")

**Cleanup Checklist:**
1. List all test users created during session
2. Delete each test user via DELETE /users/{id} endpoint
3. Verify deletion with GET request (should return 404)
4. Document any users that couldn't be deleted
5. Clear test data from any dependent systems

**Post-Test Verification:**
- Confirm test environment returned to clean state
- Verify no test data remains in database
- Check that test didn't affect production data
- Reset any modified configuration settings

**5. Environment Management**

**Manual Environment Configuration:**

**Environment Settings Documentation:**
- **Base URL:** `https://api-staging.example.com`
- **Authentication:** Test API key or bearer token
- **Timeout:** 30 seconds for all requests
- **Retry Policy:** 3 attempts for failed requests

**Environment-Specific Test Configurations:**

**Staging Environment:**
- **Concurrent Users:** Maximum 10 simultaneous requests
- **Rate Limit:** 100 requests per minute
- **Data Persistence:** Temporary (cleaned daily)
- **Monitoring:** Enhanced logging enabled

**Production Environment:**
- **Concurrent Users:** Maximum 5 simultaneous requests  
- **Rate Limit:** 50 requests per minute
- **Data Persistence:** Permanent (requires careful cleanup)
- **Monitoring:** Minimal testing during off-peak hours

**Environment Configuration Checklist:**
1. ‚úÖ Verify correct base URL for target environment
2. ‚úÖ Confirm authentication token is valid
3. ‚úÖ Test network connectivity and timeouts
4. ‚úÖ Validate rate limiting thresholds
5. ‚úÖ Review data cleanup policies
6. ‚úÖ Check monitoring and logging setup

### Common API Testing Challenges

**1. Dynamic Data**
```python
# Challenge: Testing with changing data
def test_dynamic_data():
    # ‚ùå Problem: Data might change between test runs
    response = requests.get('/users')
    users = response.json()
    assert len(users) == 5  # This might fail if data changes
    
    **‚úÖ Solution: Create Your Own Test Data**

**Manual Test Data Creation:**
1. **Create Test Users:**
   - Send POST /users with `{"name": "TestUser1"}`
   - Send POST /users with `{"name": "TestUser2"}`  
   - Send POST /users with `{"name": "TestUser3"}`
   - Record each user ID returned

2. **Test with Your Data:**
   - Send GET /users to retrieve all users
   - Manually verify your 3 test users are present
   - Check user IDs match the ones you created
   - Confirm user names are "TestUser1", "TestUser2", "TestUser3"

3. **Cleanup:**
   - Delete each test user using DELETE /users/{id}
   - Verify deletion with GET requests

**2. Asynchronous Operations**

**Manual Testing of Async Operations:**

**Test Case: Bulk Import Operation**

**Step 1: Initiate Async Operation**
- Send POST /users/bulk-import with `{"file_url": "test_data.csv"}`
- Verify response status is 202 (Accepted)
- Record the job_id from response body

**Step 2: Manual Polling for Completion**
- **Polling Strategy:** Check status every 2 seconds
- **Maximum Wait Time:** 60 seconds
- **Poll Endpoint:** GET /jobs/{job_id}/status

**Manual Polling Checklist:**
1. ‚úÖ Send GET /jobs/{job_id}/status
2. ‚úÖ Record response status and job state
3. ‚úÖ If status is "pending" or "running", wait 2 seconds
4. ‚úÖ Repeat until status is "completed" or "failed"
5. ‚úÖ If 60 seconds elapsed, document timeout issue

**Step 3: Manual Status Verification**
- **Completion Check:** Job status should be "completed"
- **Failure Handling:** If status is "failed", document error details
- **Timeout Handling:** If 60 seconds pass, document timeout issue

**Step 4: Results Verification**
- Send GET /jobs/{job_id}/results
- Verify response status is 200
- Check results match expected bulk import outcome
- Validate imported data appears in system

**Async Testing Documentation Template:**
```
Test: Bulk Import Operation
Job ID: [record_here]
Start Time: [timestamp]
Completion Time: [timestamp]
Status Checks: [list each polling attempt]
Final Status: [completed/failed/timeout]
Results Verified: [yes/no]
Issues Found: [document any problems]
```

**3. Rate Limiting**

**Manual Rate Limiting Testing:**

**Test Objective:** Verify API enforces rate limits properly

**Test Approach:**
1. **Baseline Testing:** Send normal requests to establish baseline
2. **Load Testing:** Gradually increase request frequency
3. **Threshold Testing:** Exceed rate limit to trigger 429 responses
4. **Recovery Testing:** Verify system recovers after rate limit period

**Manual Rate Limiting Test Process:**

**Phase 1: Normal Request Testing**
- Send 10 requests to GET /api/data with 1-second intervals
- Record response times and status codes
- All should return 200 OK

**Phase 2: Increased Load Testing**
- Send 50 requests with 0.5-second intervals
- Monitor for any rate limiting warnings
- Document response patterns

**Phase 3: Rate Limit Threshold Testing**
- Send 150 rapid requests (as fast as possible)
- Count successful requests (200 status)
- Count rate-limited requests (429 status)
- Record at what point rate limiting begins
            # Wait before continuing
            time.sleep(1)
        else:
            raise AssertionError(f"Unexpected status code: {response.status_code}")
    
    # Verify rate limiting works
    assert rate_limited_requests > 0
    assert successful_requests > 0
```

---

## API Testing Tools

### 1. Postman (Manual Testing Focus)

**Classification:** Manual Testing Tool

**Features for Manual Testing:**
- GUI-based interface for easy manual request creation
- Collection organization for grouping related tests
- Environment variables for different test environments
- Manual response inspection and validation
- Team collaboration on manual test collections
- Mock servers for testing without backend

**Manual Testing with Postman:**

**1. Basic Manual Request Setup:**
- **Step 1:** Create new request in Postman
- **Step 2:** Set request method (GET, POST, PUT, DELETE)
- **Step 3:** Enter API endpoint URL
- **Step 4:** Add headers manually (Content-Type, Authorization)
- **Step 5:** Add request body (JSON/XML) if needed
- **Step 6:** Send request and inspect response

**2. Manual Response Validation:**
- **Status Code Check:** Verify response shows expected status (200, 201, 400, etc.)
- **Response Time:** Check response time is under acceptable threshold
- **Response Body:** Manually inspect JSON/XML structure and data
- **Headers:** Verify response headers contain expected values

**3. Manual Data-Driven Testing:**
- **Create Test Cases:** Document different input scenarios in Excel/CSV
- **Manual Execution:** Run each test case manually in Postman
- **Results Tracking:** Document pass/fail results for each scenario

**Manual Testing Checklist for Postman:**
- ‚úÖ Request method is correct
- ‚úÖ URL is properly formatted
- ‚úÖ Headers are set correctly
- ‚úÖ Request body is valid JSON/XML
- ‚úÖ Status code matches expectation
- ‚úÖ Response contains required fields
- ‚úÖ Response time is acceptable
- ‚úÖ Error responses are meaningful

### 2. Manual Testing Alternatives to Automation Tools

**Instead of REST Assured/Automation Tools, Use Manual Approaches:**

**Manual Test Planning:**
1. **Create Test Matrix:** Document all test scenarios in spreadsheet
2. **Environment Setup:** Configure Postman environments for different servers
3. **Test Data Preparation:** Prepare valid/invalid data sets for manual testing
4. **Execution Tracking:** Use simple checklist format for manual execution

**Manual Test Execution Process:**
1. **Test Case Setup:** Open Postman, select appropriate environment
2. **Request Configuration:** Manually configure each request parameter
3. **Response Verification:** Visually inspect response data and status
4. **Result Documentation:** Record pass/fail status with screenshots
5. **Issue Reporting:** Create detailed bug reports for failures

**Manual Testing Benefits:**
- **Exploratory Testing:** Can discover unexpected issues through human observation
- **Usability Validation:** Can assess API ease-of-use from developer perspective
- **Context Awareness:** Human testers can apply business logic during testing
- **No Code Maintenance:** No scripts to maintain or debug
   - **Manual Test Scenarios:**
     - User Creation (Valid/Invalid data)
     - User Retrieval by ID
     - User Update operations
     - User Deletion
     - Authentication scenarios

2. **Manual Validation Checklist (Instead of Assertions):**
   ```
   ‚úÖ Status Code Verification:
   - Success: 200, 201, 204
   - Client Errors: 400, 401, 403, 404
   - Server Errors: 500, 502, 503
   
   ‚úÖ Response Header Verification:
   - Content-Type: application/json
   - Cache-Control settings
   - CORS headers when applicable
   
   ‚úÖ Response Body Validation:
   - Required fields present (id, name, email)
   - Data types correct (numbers, strings, booleans)
   - Email format contains "@"
   - No sensitive data exposed
   ```

3. **Manual Data-Driven Testing Approach:**
   
   **Create Multiple Postman Requests for Different Data Sets:**
   
   **Valid User Creation Test:**
   - POST `/api/users`
   - Body: `{"name": "John Doe", "email": "john@test.com", "age": 30}`
   - Expected: 201 Created
   
   **Invalid Name Test:**
   - POST `/api/users`
   - Body: `{"name": "", "email": "john@test.com", "age": 30}`
   - Expected: 400 Bad Request
   
   **Invalid Email Test:**
   - POST `/api/users`
   - Body: `{"name": "John Doe", "email": "invalid-email", "age": 30}`
   - Expected: 400 Bad Request
   
   **Invalid Age Test:**
   - POST `/api/users`
   - Body: `{"name": "John Doe", "email": "john@test.com", "age": -5}`
   - Expected: 400 Bad Request

4. **Manual Browser Console Testing (Alternative to Python):**
   ```javascript
   // Test user creation in browser console
   fetch('/api/users', {
       method: 'POST',
       headers: {'Content-Type': 'application/json'},
       body: JSON.stringify({name: "John Doe", email: "john@test.com", age: 30})
   })
   .then(response => {
       console.log('Status:', response.status);
       return response.json();
   })
   .then(data => console.log('User created:', data));
   ```

5. **Manual Test Cleanup Procedures:**
   - Track created test data manually
   - Delete test users after each test session
   - Reset test environment between test runs
   - Verify data cleanup with GET requests

### 4. Karate Framework

**Note:** Converted to focus on **manual testing approaches** instead of automation frameworks.

**Manual Alternatives to Karate Framework:**

**Instead of Automated Feature Files, Use Manual Test Documentation:**

1. **Manual Test Scenarios (BDD-Style Documentation):**

   **Scenario: Get user details (Manual Execution)**
   ```
   Given: API endpoint https://api.example.com/users/1
   And: Authorization header with valid token
   When: I send GET request using Postman/cURL
   Then: I should receive status 200
   And: Response should contain:
        - id: (number) 1
        - name: (string) "John Doe"  
        - email: (string) with @ symbol
        - age: (number) valid age value
   ```

   **Scenario: Create new user (Manual Execution)**
   ```
   Given: API endpoint https://api.example.com/users
   And: Valid user data:
        {
          "name": "Jane Smith",
          "email": "jane@example.com", 
          "age": 25
        }
   When: I send POST request using Postman
   Then: I should receive status 201 Created
   And: Response should include:
        - Generated user ID (number)
        - Echoed name: "Jane Smith"
        - Echoed email: "jane@example.com"
   ```

2. **Manual Data-Driven Testing Approach:**

   **Test Case Matrix for User Validation:**
   
   | Test # | Name | Email | Age | Expected Status | Manual Test Method |
   |--------|------|-------|-----|----------------|-------------------|
   | 1 | "John" | "john@test.com" | 30 | 201 Created | Postman POST request |
   | 2 | "" (empty) | "missing@test.com" | 30 | 400 Bad Request | Postman POST request |
   | 3 | "Bob" | "invalid-email" | 30 | 400 Bad Request | Postman POST request |
   | 4 | "Alice" | "alice@test.com" | -5 | 400 Bad Request | Postman POST request |

   **Manual Execution Steps:**
   1. Open Postman
   2. Create POST request to `/api/users`
   3. For each test case, update request body with test data
   4. Send request and verify expected status code
   5. Document actual results vs expected results

3. **Manual Browser Console Testing (Alternative to Karate):**
   ```javascript
   // Manual test execution in browser console
   
   // Test 1: Valid user creation
   fetch('/api/users', {
       method: 'POST',
       headers: {'Content-Type': 'application/json'},
       body: JSON.stringify({name: "John", email: "john@test.com", age: 30})
   }).then(response => console.log('Test 1 Status:', response.status));
   
   // Test 2: Invalid email
   fetch('/api/users', {
       method: 'POST', 
       headers: {'Content-Type': 'application/json'},
       body: JSON.stringify({name: "Bob", email: "invalid-email", age: 30})
   }).then(response => console.log('Test 2 Status:', response.status));
   ```

4. **Manual Test Reporting Template:**
   ```
   Test Run Date: [DATE]
   Test Environment: [STAGING/PRODUCTION]
   Tester: [NAME]
   
   Test Results:
   ‚úÖ PASS: Get user details - Status 200, correct data format
   ‚úÖ PASS: Create valid user - Status 201, user created with ID
   ‚ùå FAIL: Create user with invalid email - Expected 400, got 500
   ‚úÖ PASS: Create user with empty name - Status 400, proper validation
   
   Issues Found:
   - Server error on invalid email instead of validation error
   - Consider improving error message clarity
   ```

### 5. Newman (Postman CLI)

**Features:**
- Command-line execution of Postman collections
- CI/CD integration
- Multiple output formats
- Environment support

**Newman Examples:**

```bash
# Basic collection run
newman run collection.json

# With environment and globals
newman run collection.json \
  --environment environment.json \
  --globals globals.json

# Generate reports
newman run collection.json \
  --reporters cli,html,json \
  --reporter-html-export results.html

# CI/CD integration
newman run collection.json \
  --environment production.json \
  --bail \
  --color off
```

### 6. Advanced Tools

**Insomnia:**
- **Classification:** Manual Testing Tool
- Alternative to Postman for manual API testing
- Great for GraphQL manual testing
- Plugin ecosystem for enhanced manual testing

**Thunder Client (VS Code):**
- **Classification:** Manual Testing Tool  
- Lightweight alternative to Postman
- Integrated with VS Code for developers
- Great for quick manual API testing

**k6 (Performance Testing):**
**Note:** Converted to manual performance testing approaches.

**Manual Performance Testing Alternatives to k6:**

**Instead of Automated Load Scripts, Use Manual Performance Testing:**

1. **Postman Collection Runner for Manual Load Testing:**
   ```
   Setup:
   - Create simple GET request to https://api.example.com/users
   - Use Collection Runner with settings:
     * Iterations: 100 (simulates 100 requests)
     * Delay: 0ms (for concurrent-like behavior)
     * Environment: Production/Staging
   
   Manual Monitoring:
   - Watch response times in Collection Runner results
   - Identify requests taking >500ms
   - Note any failed requests (status != 200)
   - Calculate average response time manually
   ```

2. **Browser Console Manual Performance Testing:**
   ```javascript
   // Manual performance test in browser console
   async function manualLoadTest() {
       const results = [];
       console.log('Starting manual load test...');
       
       for (let i = 0; i < 50; i++) {
           const startTime = Date.now();
           try {
               const response = await fetch('https://api.example.com/users');
               const endTime = Date.now();
               const responseTime = endTime - startTime;
               
               results.push({
                   request: i + 1,
                   status: response.status,
                   responseTime: responseTime,
                   success: response.status === 200
               });
               
               console.log(`Request ${i + 1}: ${response.status} - ${responseTime}ms`);
           } catch (error) {
               console.error(`Request ${i + 1} failed:`, error);
           }
       }
       
       // Manual analysis
       const successfulRequests = results.filter(r => r.success);
       const averageResponseTime = successfulRequests.reduce((sum, r) => sum + r.responseTime, 0) / successfulRequests.length;
       
       console.log('=== Manual Load Test Results ===');
       console.log(`Total Requests: ${results.length}`);
       console.log(`Successful: ${successfulRequests.length}`);
       console.log(`Failed: ${results.length - successfulRequests.length}`);
       console.log(`Average Response Time: ${averageResponseTime.toFixed(2)}ms`);
       console.log(`Success Rate: ${(successfulRequests.length / results.length * 100).toFixed(2)}%`);
   }
   
   // Run the manual test
   manualLoadTest();
   ```

3. **Manual Performance Testing Checklist:**
   ```
   Performance Test Objectives:
   ‚úÖ Response time under normal load (<500ms)
   ‚úÖ API handles concurrent requests (50+ simultaneous)
   ‚úÖ Success rate above 95%
   ‚úÖ No memory leaks during extended testing
   ‚úÖ Graceful degradation under high load
   ‚úÖ Appropriate error messages for failed requests
   
   Manual Testing Tools:
   - Postman Collection Runner for batch requests
   - Browser Developer Tools for timing analysis
   - Multiple browser tabs for concurrent simulation
   - Network throttling for different connection speeds
   ```

---

## Test Design and Strategy

### Test Pyramid for APIs

```
    /\
   /UI\      <- Few UI tests (E2E workflows)
  /____\
 /      \
/  API   \    <- More API tests (Business logic)
\        /
 \______/
/        \
/  Unit   \   <- Most unit tests (Functions/methods)
\__________/
```

### API Test Strategy

**1. Risk-Based Testing:**
- Identify critical business flows
- Prioritize high-risk areas
- Focus on data integrity
- Test error scenarios

**2. Test Categories:**

**Happy Path Tests (30%):**

**Manual Test Case: Successful User Registration**

**Test Objective:** Verify user can successfully register with valid data

**Test Steps:**
1. **Prepare Test Data:**
   - Name: "John Doe"
   - Email: "john@example.com" 
   - Password: "SecurePass123!"

2. **Execute Request:**
   - Send POST to /api/register
   - Include JSON body with test data
   - Record response time

3. **Verify Response:**
   - ‚úÖ Status code is 201 (Created)
   - ‚úÖ Response body contains user ID
   - ‚úÖ Email in response matches input email
   - ‚úÖ Password not returned in response
   - ‚úÖ Response time under 2 seconds

**Edge Cases (40%):**

**Manual Edge Case Testing:**

**Test Case 1: Empty Name Field**
- *Input:* `{"name": "", "email": "test@example.com", "password": "pass123"}`
- *Expected:* 400 status, error about empty name
- *Verify:* Error message mentions name requirement

**Test Case 2: Invalid Email Format**
- *Input:* `{"name": "John", "email": "invalid-email", "password": "pass123"}`
- *Expected:* 400 status, email validation error
- *Verify:* Error message specifies email format issue

**Test Case 3: Weak Password**
- *Input:* `{"name": "John", "email": "test@example.com", "password": "123"}`
- *Expected:* 400 status, password strength error
- *Verify:* Error message explains password requirements

**Test Case 4: Name Too Long**
- *Input:* Name field with 256 characters
- *Expected:* 400 status, name length error
- *Verify:* Error message mentions character limit

**Edge Case Testing Checklist:**
- ‚úÖ Test each validation rule individually
- ‚úÖ Record actual vs expected error messages
- ‚úÖ Verify error response structure consistency
- ‚úÖ Check HTTP status codes are appropriate
- ‚úÖ Document any unexpected behaviors

**Error Scenarios (30%):**

**Manual Error Scenario Testing:**

**Test Case: Duplicate User Registration**
        "name": "John Doe",
        "email": "existing@example.com",
        "password": "SecurePass123!"
    }
  **Test Objective:** Verify system prevents duplicate user registration

**Test Steps:**
1. **First Registration:**
   - Send POST /api/register with unique test data
   - Verify 201 status (successful registration)
   - Record user details for duplicate attempt

2. **Duplicate Registration Attempt:**
   - Send POST /api/register with exact same data
   - Verify 409 status (Conflict)
   - Check error message contains "already exists"

3. **Cleanup:**
   - Delete the test user created
   - Verify deletion was successful

**Error Scenario Documentation:**
```
Test: Duplicate Registration Prevention
First Registration: [timestamp] - Status: 201
Duplicate Attempt: [timestamp] - Status: 409
Error Message: "[record actual message]"
Cleanup Status: [completed/failed]
```

### Test Data Management

**1. Test Data Categories:**
- **Static Data:** Predefined test datasets stored in files
- **Dynamic Data:** Generated fresh for each test execution
- **External Data:** Retrieved from external sources (files, databases, APIs)

**2. Manual Test Data Strategies:**

**Test Data Factory Approach (Manual):**

**User Test Data Templates:**
```json
{
  "valid_user_template": {
    "name": "Test User [timestamp]",
    "email": "testuser[timestamp]@example.com",
    "age": 25,
    "phone": "+1-555-0123"
  },
  "invalid_user_templates": [
    {"name": "", "email": "test@example.com", "age": 25},
    {"name": "Test", "email": "invalid-email", "age": 25},
    {"name": "Test", "email": "test@example.com", "age": -1}
  ]
}
```

**Manual Data Generation Process:**
1. **Unique Identifiers:** Use timestamps or random numbers
2. **Email Uniqueness:** Append timestamp to email addresses
3. **Phone Numbers:** Use test phone number formats
4. **Names:** Use clearly identifiable test prefixes

**Test Data Management Checklist:**
- ‚úÖ Ensure test data is clearly identifiable
- ‚úÖ Use unique identifiers to avoid conflicts
- ‚úÖ Prepare both valid and invalid datasets
- ‚úÖ Document data requirements for each test
- ‚úÖ Plan cleanup strategy for test data

**Manual Test Data Creation:**

**Admin User Test Data:**
```json
{
  "admin_user_template": {
    "name": "Admin Test User [timestamp]",
    "email": "admin[timestamp]@example.com",
    "role": "admin",
    "permissions": ["read", "write", "delete"],
    "age": 30
  }
}
```

**Test Data Usage in Manual Testing:**
1. **Prepare Test Data:** Create JSON templates for different user types
2. **Customize Data:** Replace [timestamp] with actual values
3. **Execute Test:** Send POST /api/users with prepared data
4. **Verify Creation:** Check 201 status and response structure
5. **Cleanup:** Delete test user after test completion

**Builder Pattern:**
```python
class UserBuilder:
    def __init__(self):
        self.user_data = {}
    
    def with_name(self, name):
        self.user_data["name"] = name
        return self
    
    def with_email(self, email):
        self.user_data["email"] = email
        return self
    
    def with_age(self, age):
        self.user_data["age"] = age
        return self
    
    def build(self):    return self.user_data

**Manual Builder Pattern Usage:**

**Test Data Construction Process:**
1. **Start with Base Template:** Use standard user data template
2. **Customize Required Fields:** 
   - Name: "John Doe"
   - Email: "john@example.com"
   - Age: 30
3. **Build Final Test Data:** Combine all fields into JSON
4. **Execute Test:** Send POST /api/users with constructed data
5. **Verify Response:** Check 201 status and response structure

**Manual Test Data Builder Checklist:**
- ‚úÖ Start with complete data template
- ‚úÖ Modify only necessary fields for test case
- ‚úÖ Ensure all required fields are present
- ‚úÖ Validate data before sending request
- ‚úÖ Document the data construction process

### Environment Management

**Manual Environment Configuration:**
    **Environment Configuration Settings:**

**Development Environment:**
- **Base URL:** `http://localhost:3000`
- **API Key:** `dev-key-123`
- **Timeout:** 30 seconds
- **Retry Attempts:** 3

**Staging Environment:**
- **Base URL:** `https://staging-api.example.com`
- **API Key:** Environment variable `STAGING_API_KEY`
- **Timeout:** 10 seconds
- **Retry Attempts:** 2

**Production Environment:**
- **Base URL:** `https://api.example.com`
- **API Key:** Environment variable `PROD_API_KEY`
- **Timeout:** 5 seconds
- **Retry Attempts:** 1 (careful testing only)

**Manual Environment Setup Checklist:**
1. ‚úÖ Verify correct base URL for target environment
2. ‚úÖ Confirm API key is valid and has proper permissions
3. ‚úÖ Test connectivity with simple GET request
4. ‚úÖ Validate timeout settings work as expected
5. ‚úÖ Document retry behavior for failed requests
6. ‚úÖ Ensure environment-specific test data is available
            timeout=30,
            retry_attempts=3
        ),
        "staging": APIConfig(
            base_url="https://staging-api.example.com",
            api_key=os.getenv("STAGING_API_KEY"),
            timeout=10,
            retry_attempts=2
        ),
        "production": APIConfig(
            base_url="https://api.example.com",
            api_key=os.getenv("PROD_API_KEY"),
            timeout=5,
            retry_attempts=1
        )
    }
    
    return configs[env]
```

---

## Advanced Testing Concepts

### 1. API Versioning Testing

**Versioning Strategies:**
- URL versioning: `/api/v1/users`
- Header versioning: `Accept: application/vnd.api.v1+json`
- Parameter versioning: `/api/users?version=1`

**Testing Multiple Versions:**
```python
@pytest.mark.parametrize("version", ["v1", "v2"])
def test_user_api_versions(version):
    response = requests.get(f"/api/{version}/users/1")
    
    if version == "v1":
        assert "full_name" in response
    elif version == "v2":
        assert "first_name" in response
        assert "last_name" in response
```

### 2. Microservices Testing

**Service Dependencies:**
```python
class UserServiceTest:
    def setup_method(self):
        # Start dependent services or use mocks
        self.auth_service_mock = AuthServiceMock()
        self.email_service_mock = EmailServiceMock()
    
    def test_user_registration_flow(self):
        # Setup mocks
        self.auth_service_mock.setup_response("/validate-token", 200, {"valid": True})
        self.email_service_mock.setup_response("/send-welcome", 200, {"sent": True})
        
        # Test user service
        response = requests.post("/api/users", json=user_data)
        
        # Verify interactions
        assert self.auth_service_mock.was_called("/validate-token")
        assert self.email_service_mock.was_called("/send-welcome")
```

### 3. Event-Driven Architecture Testing

**Message Queue Testing:**
```python
def test_user_created_event():
    # Create user
    response = requests.post("/api/users", json=user_data)
    user_id = response.json()["id"]
    
    # Verify event was published
    events = message_queue.get_events("user.created")
    assert len(events) == 1
    assert events[0]["user_id"] == user_id
    assert events[0]["event_type"] == "user.created"
```

### 4. Database Testing

**Data Verification:**
```python
def test_user_creation_database_verification():
    # Create user via API
    response = requests.post("/api/users", json=user_data)
    user_id = response.json()["id"]
    
    # Verify in database
    user_in_db = database.query(f"SELECT * FROM users WHERE id = {user_id}")
    assert user_in_db["name"] == user_data["name"]
    assert user_in_db["email"] == user_data["email"]
    
    # Verify audit log
    audit_logs = database.query(f"SELECT * FROM audit_logs WHERE user_id = {user_id}")
    assert len(audit_logs) == 1
    assert audit_logs[0]["action"] == "user_created"
```

### 5. Caching Testing

**Cache Verification:**
```python
def test_user_caching():
    # First request (cache miss)
    start_time = time.time()
    response1 = requests.get("/api/users/1")
    first_request_time = time.time() - start_time
    
    # Second request (cache hit)
    start_time = time.time()
    response2 = requests.get("/api/users/1")
    second_request_time = time.time() - start_time
    
    # Verify responses are identical
    assert response1.json() == response2.json()
    
    # Verify second request was faster (cached)
    assert second_request_time < first_request_time * 0.5
    
    # Verify cache headers
    assert response2.headers.get("X-Cache") == "HIT"
```

---

## üß∞ Advanced API Testing Techniques

### Contract Testing

**What it is:** Contract testing ensures that services can communicate with each other by testing the "contract" or agreement between them.

**Analogy:** Like testing that a key fits a lock before manufacturing millions of copies. You verify the interface works before building the full system.

**Consumer-Driven Contract Testing with Pact:**

```python
# Consumer test (Frontend team)
import pact

pact = Pact(
    consumer="UserInterface",
    provider="UserService"
)

def test_get_user_contract():
    expected = {
        "id": Matcher.like(123),
        "name": Matcher.like("John Doe"),
        "email": Matcher.like("john@example.com"),
        "created_at": Matcher.regex(r"\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z")
    }
    
    (pact
     .given("User with ID 123 exists")
     .upon_receiving("Get user request")
     .with_request("GET", "/users/123")
     .will_respond_with(200, body=expected))
    
    with pact:
        response = requests.get("http://localhost:1234/users/123")
        assert response.status_code == 200
        user = response.json()
        assert user["id"] == 123
```

```python
# Provider test (Backend team)
def test_user_service_honors_contract():
    # Verify that actual service meets the contract
    response = requests.get("https://actual-api.com/users/123")
    assert response.status_code == 200
    
    user = response.json()
    assert "id" in user
    assert "name" in user
    assert "email" in user
    assert "created_at" in user
    
    # Validate data types and formats
    assert isinstance(user["id"], int)
    assert "@" in user["email"]
    assert re.match(r"\d{4}-\d{2}-\d{2}T", user["created_at"])
```

### Schema Testing

**JSON Schema Validation:**
```python
import jsonschema

def test_response_schema():
    user_schema = {
        "type": "object",
        "properties": {
            "id": {"type": "integer", "minimum": 1},
            "name": {"type": "string", "minLength": 1, "maxLength": 100},
            "email": {"type": "string", "format": "email"},
            "age": {"type": "integer", "minimum": 0, "maximum": 150},
            "address": {
                "type": "object",
                "properties": {
                    "street": {"type": "string"},
                    "city": {"type": "string"},
                    "zipcode": {"type": "string", "pattern": "^[0-9]{5}$"}
                },
                "required": ["street", "city", "zipcode"]
            }
        },
        "required": ["id", "name", "email"]
    }
    
    response = requests.get("/api/users/123")
    user_data = response.json()
    
    # Validate against schema
    try:
        jsonschema.validate(user_data, user_schema)
    except jsonschema.ValidationError as e:
        pytest.fail(f"Response doesn't match schema: {e.message}")
```

**OpenAPI/Swagger Schema Testing:**
```python
import openapi_spec_validator
import yaml

def test_openapi_schema_compliance():
    # Load API specification
    with open("api-spec.yaml") as f:
        spec = yaml.safe_load(f)
    
    # Validate spec itself
    openapi_spec_validator.validate_spec(spec)
    
    # Test actual API against spec
    response = requests.get("/api/users/123")
    user_data = response.json()
    
    # Get schema for this endpoint from spec
    user_schema = spec["components"]["schemas"]["User"]
    
    # Validate response against schema
    jsonschema.validate(user_data, user_schema)
```

### API Mocking and Virtualization

**Creating Mock Services:**
```python
from unittest.mock import Mock, patch
import responses

# Using responses library for HTTP mocking
@responses.activate
def test_with_mocked_external_api():
    # Mock external service response
    responses.add(
        responses.GET,
        "https://external-service.com/api/data",
        json={"status": "success", "data": [1, 2, 3]},
        status=200
    )
    
    # Test your API that depends on external service
    response = requests.get("/api/internal-endpoint")
    assert response.status_code == 200
    
    # Verify external service was called
    assert len(responses.calls) == 1
    assert responses.calls[0].request.url == "https://external-service.com/api/data"
```

**WireMock for Advanced Mocking:**
```python
from wiremock import WiremockClient

def test_with_wiremock():
    # Start WireMock server
    wiremock = WiremockClient("http://localhost:8089")
    
    # Set up mock response
    wiremock.stub_for({
        "request": {
            "method": "GET",
            "urlPattern": "/api/users/.*"
        },
        "response": {
            "status": 200,
            "headers": {"Content-Type": "application/json"},
            "jsonBody": {"id": 123, "name": "Mocked User"},
            "fixedDelayMilliseconds": 1000  # Simulate slow response
        }
    })
    
    # Test with mock
    response = requests.get("http://localhost:8089/api/users/123")
    assert response.status_code == 200
    assert response.json()["name"] == "Mocked User"
```

### Database Testing with APIs

**Database State Testing:**
```python
import psycopg2

class APIWithDatabaseTest:
    def setUp(self):
        self.db_connection = psycopg2.connect(
            host="localhost",
            database="test_db",
            user="test_user",
            password="test_pass"
        )
        self.setup_test_data()
    
    def tearDown(self):
        self.cleanup_test_data()
        self.db_connection.close()
    
    def test_create_user_database_consistency(self):
        # Initial database state
        initial_count = self.get_user_count()
        
        # API call
        user_data = {"name": "Test User", "email": "test@example.com"}
        response = requests.post("/api/users", json=user_data)
        assert response.status_code == 201
        
        user_id = response.json()["id"]
        
        # Verify database state changed
        final_count = self.get_user_count()
        assert final_count == initial_count + 1
        
        # Verify data in database matches API response
        db_user = self.get_user_from_db(user_id)
        assert db_user["name"] == user_data["name"]
        assert db_user["email"] == user_data["email"]
    
    def get_user_count(self):
        cursor = self.db_connection.cursor()
        cursor.execute("SELECT COUNT(*) FROM users")
        return cursor.fetchone()[0]
    
    def get_user_from_db(self, user_id):
        cursor = self.db_connection.cursor()
        cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))
        row = cursor.fetchone()
        return {"id": row[0], "name": row[1], "email": row[2]}
```

### Microservices Testing

**Service Communication Testing:**
```python
def test_microservice_communication():
    # Test User Service ‚Üí Order Service communication
    
    # Step 1: Create user in User Service
    user_response = requests.post("http://user-service/api/users", json={
        "name": "Test User",
        "email": "test@example.com"
    })
    assert user_response.status_code == 201
    user_id = user_response.json()["id"]
    
    # Step 2: Create order in Order Service (should call User Service to validate user)
    order_response = requests.post("http://order-service/api/orders", json={
        "user_id": user_id,
        "product": "laptop",
        "quantity": 1
    })
    assert order_response.status_code == 201
    
    # Step 3: Verify order details include user information
    order_id = order_response.json()["id"]
    order_details = requests.get(f"http://order-service/api/orders/{order_id}")
    
    order_data = order_details.json()
    assert order_data["user"]["id"] == user_id
    assert order_data["user"]["name"] == "Test User"
```

**Circuit Breaker Testing:**
```python
def test_circuit_breaker_behavior():
    # Test when dependent service is down
    
    # Simulate external service failure
    for i in range(10):  # Trigger circuit breaker
        response = requests.get("/api/orders")
        # Should start failing after threshold is reached
        if i > 5:
            assert response.status_code == 503  # Service Unavailable
            assert "Circuit breaker open" in response.json()["message"]
    
    # Test fallback behavior
    response = requests.get("/api/orders")
    assert response.status_code == 200
    assert response.json()["source"] == "cache"  # Fallback to cached data
```

### Event-Driven Architecture Testing

**Message Queue Testing:**
```python
import pika  # RabbitMQ client

def test_event_driven_workflow():
    # Setup message queue connection
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()
    
    # Declare test queue
    channel.queue_declare(queue='test_events')
    
    # API call that should trigger an event
    response = requests.post("/api/users", json={
        "name": "Test User",
        "email": "test@example.com"
    })
    assert response.status_code == 201
    
    # Wait for and verify event was published
    time.sleep(1)  # Allow time for async processing
    
    method, properties, body = channel.basic_get(queue='test_events')
    assert method is not None  # Message was received
    
    event_data = json.loads(body)
    assert event_data["event_type"] == "user_created"
    assert event_data["user_id"] == response.json()["id"]
    
    connection.close()
```

### API Versioning Testing

**Version Compatibility Testing:**
```python
def test_api_version_compatibility():
    test_cases = [
        # (version, endpoint, expected_status, expected_fields)
        ("v1", "/api/v1/users/123", 200, ["id", "name", "email"]),
        ("v2", "/api/v2/users/123", 200, ["id", "name", "email", "created_at"]),
        ("v3", "/api/v3/users/123", 200, ["id", "full_name", "email_address", "created_at", "updated_at"]),
    ]
    
    for version, endpoint, expected_status, expected_fields in test_cases:
        response = requests.get(f"https://api.example.com{endpoint}")
        assert response.status_code == expected_status
        
        user_data = response.json()
        for field in expected_fields:
            assert field in user_data, f"Field {field} missing in API {version}"
```

**Backward Compatibility Testing:**
```python
def test_backward_compatibility():
    # Test that old API versions still work
    v1_response = requests.get("/api/v1/users/123")
    v2_response = requests.get("/api/v2/users/123")
    
    assert v1_response.status_code == 200
    assert v2_response.status_code == 200
    
    v1_data = v1_response.json()
    v2_data = v2_response.json()
    
    # Ensure v1 fields are present in v2 (backward compatibility)
    for field in v1_data.keys():
        assert field in v2_data or field_has_equivalent_in_v2(field, v2_data)
```

### GraphQL Testing

**GraphQL Query Testing:**
```python
def test_graphql_query():
    query = """
    query GetUser($userId: ID!) {
        user(id: $userId) {
            id
            name
            email
            posts {
                id
                title
                content
            }
        }
    }
    """
    
    variables = {"userId": "123"}
    
    response = requests.post("/graphql", json={
        "query": query,
        "variables": variables
    })
    
    assert response.status_code == 200
    
    data = response.json()
    assert "errors" not in data
    
    user = data["data"]["user"]
    assert user["id"] == "123"
    assert "name" in user
    assert "posts" in user
    assert isinstance(user["posts"], list)
```

**GraphQL Mutation Testing:**
```python
def test_graphql_mutation():
    mutation = """
    mutation CreateUser($input: CreateUserInput!) {
        createUser(input: $input) {
            user {
                id
                name
                email
            }
            errors {
                field
                message
            }
        }
    }
    """
    
    variables = {
        "input": {
            "name": "John Doe",
            "email": "john@example.com"
        }
    }
    
    response = requests.post("/graphql", json={
        "query": mutation,
        "variables": variables
    })
    
    assert response.status_code == 200
    
    data = response.json()
    result = data["data"]["createUser"]
    
    assert result["errors"] is None or len(result["errors"]) == 0
    assert result["user"]["name"] == "John Doe"
    assert result["user"]["email"] == "john@example.com"
```

### WebSocket Testing

**Real-time Communication Testing:**
```python
import websocket
import threading
import json

def test_websocket_connection():
    messages_received = []
    
    def on_message(ws, message):
        messages_received.append(json.loads(message))
    
    def on_error(ws, error):
        print(f"WebSocket error: {error}")
    
    # Connect to WebSocket
    ws = websocket.WebSocketApp("ws://localhost:8080/ws",
                                on_message=on_message,
                                on_error=on_error)
    
    # Start WebSocket in separate thread
    ws_thread = threading.Thread(target=ws.run_forever)
    ws_thread.daemon = True
    ws_thread.start()
    
    time.sleep(1)  # Allow connection to establish
    
    # Send test message
    test_message = {"type": "test", "data": "Hello WebSocket"}
    ws.send(json.dumps(test_message))
    
    time.sleep(1)  # Allow response
    
    # Verify response received
    assert len(messages_received) > 0
    assert messages_received[0]["type"] == "response"
    
    ws.close()
```

### API Rate Limiting and Throttling

**Advanced Rate Limit Testing:**
```python
def test_rate_limiting_strategies():
    # Test different rate limiting strategies
    
    # 1. Fixed Window Rate Limiting
    def test_fixed_window():
        start_time = time.time()
        request_count = 0
        
        while time.time() - start_time < 60:  # 1 minute window
            response = requests.get("/api/data")
            request_count += 1
            
            if response.status_code == 429:
                break
        
        assert request_count <= 100  # Should hit limit around 100 requests/minute
    
    # 2. Sliding Window Rate Limiting
    def test_sliding_window():
        # Make requests at different intervals
        intervals = [0, 10, 20, 30, 40, 50]  # seconds
        
        for interval in intervals:
            time.sleep(10)  # Wait 10 seconds between bursts
            
            # Try to make 30 requests quickly
            for i in range(30):
                response = requests.get("/api/data")
                if response.status_code == 429:
                    assert i > 20  # Should allow at least 20 requests per 10-second window
                    break
    
    # 3. Token Bucket Rate Limiting
    def test_token_bucket():
        # Burst requests should be allowed initially
        burst_responses = []
        for i in range(50):  # Try burst of 50
            response = requests.get("/api/data")
            burst_responses.append(response.status_code)
        
        # Some requests should succeed (bucket had tokens)
        success_count = sum(1 for status in burst_responses if status == 200)
        assert success_count > 0
        
        # Wait for bucket to refill
        time.sleep(10)
        
        # Should be able to make more requests
        response = requests.get("/api/data")
        assert response.status_code == 200
```

---

## üß± API Security Testing

### OWASP API Security Top 10

**Note:** This section has been converted to focus on **manual security testing approaches**.

**1. Broken Object Level Authorization - Manual Testing**

**Manual Test Scenario:**
```
Setup:
1. Create two test users (User A and User B) via registration API
2. Login as User A and create a private document via Postman
3. Note the document ID from the response

Manual Test Steps:
1. Login as User B and obtain authentication token
2. Use Postman to attempt accessing User A's document:
   - GET /api/documents/{user_a_document_id}
   - Headers: Authorization: Bearer {user_b_token}
3. Expected Result: 403 Forbidden status
4. Verify: User B cannot access User A's private data

Manual Verification:
‚úÖ PASS: Returns 403 Forbidden
‚ùå FAIL: Returns 200 OK (security vulnerability found)
```

**2. Broken User Authentication - Manual Testing**

**Manual Test Scenarios:**

**Test A: No Authentication Token**
- Postman Request: GET /api/profile (no Authorization header)
- Expected: 401 Unauthorized
- Verification: Check error message is informative but not revealing

**Test B: Invalid Authentication Token**
- Postman Request: GET /api/profile  
- Headers: Authorization: Bearer invalid_token_123
- Expected: 401 Unauthorized

**Test C: Expired Token Testing**
- Use an old/expired token in Postman Authorization header
- Expected: 401 Unauthorized with clear expiration message

**3. Excessive Data Exposure - Manual Testing**

**Manual Verification Process:**
```
Test Procedure:
1. Make GET request to /api/users using Postman
2. Examine response JSON structure manually
3. Check for sensitive fields that shouldn't be exposed:

Manual Security Checklist:
‚ùå Password fields present
‚ùå SSN or credit card data visible  
‚ùå Internal system fields exposed
‚ùå Admin-only information included
‚úÖ Only public fields returned (id, name, email, created_at)

Browser Console Verification:
fetch('/api/users')
.then(response => response.json())
.then(users => {
    users.forEach(user => {
        console.log('User fields:', Object.keys(user));
        if (user.password) console.error('SECURITY ISSUE: Password exposed!');
        if (user.ssn) console.error('SECURITY ISSUE: SSN exposed!');
    });
});
```

**4. Rate Limiting - Manual Testing**

**Manual Rate Limit Testing:**
```
Postman Collection Runner Method:
1. Create simple GET request to /api/users
2. Use Collection Runner with:
   - Iterations: 150 (exceed typical rate limits)
   - Delay: 0ms (rapid requests)
3. Monitor results for status code changes
4. Expected behavior:
   - First 100 requests: 200 OK
   - Requests 101+: 429 Too Many Requests
   - Response headers include rate limit info

Manual Verification Points:
‚úÖ Rate limiting triggers at documented threshold
‚úÖ 429 status code returned when limit exceeded
‚úÖ X-RateLimit-Retry-After header present
‚úÖ Rate limits reset after time window
```

**5. SQL Injection Testing - Manual Testing**

**Manual SQL Injection Test Cases:**

**Using Postman:**
```
Test malicious inputs in API parameters:

Test 1: Classic SQL Injection
- GET /api/users?name='; DROP TABLE users; --
- Expected: 400 Bad Request (input validation)

Test 2: Authentication Bypass
- GET /api/users?name=' OR '1'='1
- Expected: 400 Bad Request or properly escaped

Test 3: Union-based Injection  
- GET /api/users?name=admin'--
- Expected: 400 Bad Request

Test 4: Data Extraction Attempt
- GET /api/users?name=' UNION SELECT password FROM users WHERE '1'='1
- Expected: 400 Bad Request

Manual Verification:
‚úÖ All malicious inputs return 400 Bad Request
‚úÖ No database errors in response
‚úÖ No unexpected data returned
‚úÖ Error messages don't reveal database structure
```

**Browser Console SQL Injection Testing:**
```javascript
// Manual SQL injection testing in browser console
const maliciousInputs = [
    "'; DROP TABLE users; --",
    "' OR '1'='1",
    "admin'--"
];

maliciousInputs.forEach((input, index) => {
    fetch(`/api/users?name=${encodeURIComponent(input)}`)
    .then(response => {
        console.log(`Test ${index + 1}: ${input}`);
        console.log(`Status: ${response.status}`);
        if (response.status !== 400) {
            console.error('POTENTIAL SECURITY ISSUE: Expected 400 status');
        }
    });
});
```

### Input Validation Testing

**Manual Input Validation Testing Approaches:**

**1. Oversized Input Testing (Postman):**
```
Test Case: Large String Input
- Endpoint: POST /api/users
- Request Body: {"name": "A" repeated 10,000 times}
- Manual Steps:
  1. Create very long string (copy-paste "A" many times)
  2. Send POST request via Postman
  3. Expected: 400 Bad Request
  4. Verify: Error message mentions input size limits

Manual Test Data:
- 1KB string: Typically allowed
- 10KB string: Should be rejected
- 100KB string: Definitely should be rejected
```

**2. Special Characters Testing (Postman):**
```
Test Case: XSS Prevention
- Endpoint: POST /api/users  
- Request Body: {"name": "<script>alert('xss')</script>"}
- Manual Steps:
  1. Send malicious script in user input field
  2. Expected: 400 Bad Request OR script properly escaped
  3. Check response doesn't contain unescaped script
  4. Verify: If accepted, ensure script is encoded/sanitized

Browser Console Testing:
fetch('/api/users', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({name: "<script>alert('xss')</script>"})
})
.then(response => {
    console.log('XSS Test Status:', response.status);
    if (response.status === 200) {
        return response.json();
    }
})
.then(data => {
    if (data && data.name.includes('<script>')) {
        console.error('SECURITY ISSUE: XSS not prevented!');
    } else {
        console.log('XSS properly handled');
    }
});
```

**3. Null Byte Testing (Postman):**
```
Test Case: Null Byte Injection
- Challenge: Null bytes are tricky to test manually in GUI tools
- Alternative Approach: Use cURL command line
- Command: curl -X POST /api/users -H "Content-Type: application/json" -d '{"name": "test\u0000test"}'
- Expected: 400 Bad Request
- Manual Verification: Check logs for proper null byte handling
```

### HTTPS and TLS Testing

**Manual HTTPS and Security Testing:**

**1. HTTP to HTTPS Redirect Testing:**
```
Manual Test Steps:
1. Open browser to HTTP version: http://api.example.com/users
2. Check browser Developer Tools ‚Üí Network tab
3. Expected: 301/302 redirect to HTTPS version
4. Verify: Location header points to https://api.example.com/users
5. Confirm: Final request uses HTTPS

Browser Console Test:
fetch('http://api.example.com/users', {redirect: 'manual'})
.then(response => {
    console.log('HTTP Status:', response.status);
    console.log('Location Header:', response.headers.get('Location'));
    if (response.status === 301 && response.headers.get('Location').startsWith('https://')) {
        console.log('‚úÖ HTTPS redirect working correctly');
    } else {
        console.error('‚ùå HTTPS redirect issue detected');
    }
});
```

**2. Security Headers Testing (Browser Developer Tools):**
```
Manual Verification Process:
1. Make HTTPS request to API endpoint
2. Open Developer Tools ‚Üí Network tab ‚Üí Click on request
3. Check Response Headers for security headers:

Required Security Headers Checklist:
‚úÖ Strict-Transport-Security: max-age=31536000
‚úÖ X-Content-Type-Options: nosniff  
‚úÖ X-Frame-Options: DENY or SAMEORIGIN
‚úÖ X-XSS-Protection: 1; mode=block
‚úÖ Content-Security-Policy: (if applicable)

Browser Console Verification:
fetch('https://api.example.com/users')
.then(response => {
    console.log('=== Security Headers Check ===');
    console.log('HSTS:', response.headers.get('Strict-Transport-Security'));
    console.log('Content-Type-Options:', response.headers.get('X-Content-Type-Options'));
    console.log('Frame-Options:', response.headers.get('X-Frame-Options'));
    console.log('XSS-Protection:', response.headers.get('X-XSS-Protection'));
    
    // Flag missing security headers
    const requiredHeaders = [
        'Strict-Transport-Security',
        'X-Content-Type-Options', 
        'X-Frame-Options'
    ];
    
    requiredHeaders.forEach(header => {
        if (!response.headers.get(header)) {
            console.error(`‚ùå Missing security header: ${header}`);
        } else {
            console.log(`‚úÖ ${header} present`);
        }
    });
});
```

**3. TLS Certificate Validation (Browser):**
```
Manual Browser Testing:
1. Navigate to https://api.example.com
2. Click on lock icon in address bar
3. Check certificate details:
   ‚úÖ Valid certificate (not expired)
   ‚úÖ Issued by trusted CA
   ‚úÖ Domain name matches
   ‚úÖ Certificate chain complete
   ‚úÖ Strong encryption (TLS 1.2 or higher)

Browser Security Tab Check:
1. Open Developer Tools ‚Üí Security tab
2. Verify: "This page is secure (valid HTTPS)"
3. Check: No mixed content warnings
4. Confirm: All resources loaded over HTTPS
```

---

## üìä Performance & Load Testing

### Understanding Performance Testing

**What it is:** Performance testing evaluates how well an API performs under various conditions - like testing how many customers a restaurant can serve efficiently.

**Key Metrics to Measure:**
- **Response Time:** How fast the API responds
- **Throughput:** How many requests per second it can handle
- **Resource Usage:** CPU, memory, database connections
- **Error Rate:** Percentage of failed requests
- **Scalability:** How performance changes with increased load

### Types of Performance Testing

**1. Load Testing**
- **Purpose:** Test normal expected load
- **Example:** 100 users making requests normally
- **Goal:** Ensure system works under typical conditions

**2. Stress Testing**
- **Purpose:** Test beyond normal capacity
- **Example:** 500+ users hitting the API simultaneously
- **Goal:** Find the breaking point

**3. Spike Testing**
- **Purpose:** Test sudden load increases
- **Example:** Traffic jumps from 10 to 200 users instantly
- **Goal:** Ensure system handles traffic spikes

**4. Volume Testing**
- **Purpose:** Test with large amounts of data
- **Example:** API with millions of database records
- **Goal:** Ensure performance doesn't degrade with data growth

**5. Endurance Testing**
- **Purpose:** Test performance over extended time
- **Example:** Running load for 24 hours
- **Goal:** Detect memory leaks and gradual degradation

### Manual Performance Testing Approaches

**Manual Performance Testing with Postman:**

**1. Collection Runner Load Testing:**
```
Setup Steps:
1. Create a Collection with API requests to test
2. Set up Environment variables for different servers
3. Use Collection Runner with these settings:
   - Iterations: 100 (number of test cycles)
   - Delay: 50ms between requests (simulates user think time)
   - Data File: CSV with test data variations

Manual Monitoring:
- Watch response times in Collection Runner results
- Note any requests taking >500ms
- Document any failed requests (status != 200)
- Calculate average response time manually
- Record peak memory/CPU usage during test
```

**2. Browser Performance Testing:**
```
Manual Browser Console Performance Test:
1. Open Browser Developer Tools (F12)
2. Go to Network tab
3. Execute API calls through application UI
4. Monitor timing data for each request
5. Look for patterns in response times
6. Document bottlenecks or slow endpoints

Performance Metrics to Track:
‚úÖ First Response Time (time to first byte)
‚úÖ Total Request Duration
‚úÖ Number of Simultaneous Connections
‚úÖ Failed Request Count
‚úÖ Error Rate Percentage
```

**3. Manual Load Testing Strategy:**
```
Gradual Load Increase Process:
1. Start with 1 user (baseline performance)
2. Increase to 5 concurrent users (Postman Collection Runner)
3. Increase to 10 concurrent users (multiple browser tabs)
4. Continue increasing until performance degrades
5. Document the breaking point

Manual Observation Points:
- Response time increases significantly (>2x baseline)
- Error rates start appearing (>5%)
- Server becomes unresponsive
- Browser tabs start timing out
```

### Manual Stress Testing

**Step-by-Step Manual Stress Test:**
```
1. Baseline Test:
   - Single request to GET /api/users
   - Record: Response time, status code, payload size
   - Typical good response: <200ms, 200 OK

2. Light Load Test (5 concurrent):
   - Open 5 browser tabs
   - Execute same request simultaneously
   - Compare response times to baseline
   - Document any increases

3. Medium Load Test (10-20 concurrent):
   - Use Postman Collection Runner
   - Set iterations to 50, delay to 0ms
   - Monitor for failed requests
   - Note response time distribution

4. Heavy Load Test (50+ concurrent):
   - Coordinate multiple testers
   - Each runs Collection Runner simultaneously
   - Document system breaking point
   - Record error messages and types
```

### Manual Performance Testing Tools

**Postman Collection Runner:**
- **Purpose:** Simulate multiple API calls
- **Manual Setup:** Configure iterations and data files
- **Monitoring:** Visual graphs show response times
- **Benefits:** No coding required, easy to repeat tests

**Browser Developer Tools:**
- **Network Tab:** Shows detailed timing for each request
- **Performance Tab:** CPU and memory usage during API calls
- **Console:** Can execute custom JavaScript for testing
- **Throttling:** Simulate slow network conditions

**Manual Testing Checklist:**
```
Performance Test Plan:
‚úÖ Identify critical API endpoints
‚úÖ Define acceptable response times (<500ms)
‚úÖ Plan test scenarios (normal, peak, stress)
‚úÖ Prepare test data sets
‚úÖ Set up monitoring approach
‚úÖ Define success/failure criteria

During Testing:
‚úÖ Monitor response times continuously
‚úÖ Watch for error patterns
‚úÖ Note system resource usage
‚úÖ Document user experience impact
‚úÖ Record breaking points

Post-Testing:
‚úÖ Analyze results and trends
‚úÖ Compare against performance requirements
‚úÖ Document recommendations
‚úÖ Plan retesting after improvements
```

### Using Locust for Advanced Load Testing

**Locust Test File (locustfile.py):**
```python
from locust import HttpUser, task, between
import random

class APIUser(HttpUser):
    wait_time = between(1, 3)  # Wait 1-3 seconds between requests
    
    def on_start(self):
        """Called when user starts - login/setup"""
        # Login and get token
        response = self.client.post("/auth/login", json={
            "username": "testuser",
            "password": "testpass"
        })
        
        if response.status_code == 200:
            self.token = response.json().get("access_token")
            self.client.headers.update({"Authorization": f"Bearer {self.token}"})
    
    @task(3)  # Weight: 3 (more likely to be chosen)
    def view_users(self):
        """Simulate viewing user list"""
        self.client.get("/api/users")
    
    @task(2)  # Weight: 2
    def view_user_profile(self):
        """Simulate viewing specific user"""
        user_id = random.randint(1, 100)
        self.client.get(f"/api/users/{user_id}")
    
    @task(1)  # Weight: 1 (less frequent)
    def create_user(self):
        """Simulate creating new user"""
        user_data = {
            "name": f"TestUser{random.randint(1000, 9999)}",
            "email": f"test{random.randint(1000, 9999)}@example.com"
        }
        self.client.post("/api/users", json=user_data)
    
    @task(1)
    def search_users(self):
        """Simulate searching users"""
        search_terms = ["john", "jane", "smith", "admin"]
        term = random.choice(search_terms)
        self.client.get(f"/api/users/search?q={term}")

# Custom test scenarios
class AdminUser(HttpUser):
    wait_time = between(2, 5)
    weight = 1  # 1 admin for every 10 regular users
    
    def on_start(self):
        # Admin login
        response = self.client.post("/auth/login", json={
            "username": "admin",
            "password": "adminpass"
        })
        
        if response.status_code == 200:
            self.token = response.json().get("access_token")
            self.client.headers.update({"Authorization": f"Bearer {self.token}"})
    
    @task
    def admin_dashboard(self):
        self.client.get("/api/admin/dashboard")
    
    @task
    def manage_users(self):
        self.client.get("/api/admin/users")

class RegularUser(HttpUser):
    wait_time = between(1, 2)
    weight = 10  # 10 regular users for every 1 admin
    
    # Regular user tasks (same as APIUser above)
    pass
```

**Running Locust Tests:**
```bash
# Command line execution
locust -f locustfile.py --host=https://api.example.com

# Headless mode with specific parameters
locust -f locustfile.py --host=https://api.example.com --users 100 --spawn-rate 10 --run-time 300s --headless

# Generate HTML report
locust -f locustfile.py --host=https://api.example.com --users 100 --spawn-rate 10 --run-time 300s --headless --html performance_report.html
```

### Performance Testing with Apache Bench (ab)

**Basic Load Testing:**
```bash
# Test 1000 requests with 10 concurrent connections
ab -n 1000 -c 10 https://api.example.com/users

# With authentication header
ab -n 1000 -c 10 -H "Authorization: Bearer your_token_here" https://api.example.com/users

# POST request with JSON data
ab -n 100 -c 5 -T application/json -p post_data.json https://api.example.com/users
```

**Analyzing ab Results:**
```python
def parse_ab_results(ab_output):
    """Parse Apache Bench output"""
    results = {}
    
    for line in ab_output.split('\n'):
        if 'Requests per second' in line:
            results['requests_per_second'] = float(line.split()[3])
        elif 'Time per request' in line and 'mean' in line:
            results['avg_response_time'] = float(line.split()[3])
        elif 'Transfer rate' in line:
            results['transfer_rate'] = float(line.split()[2])
        elif 'Failed requests' in line:
            results['failed_requests'] = int(line.split()[2])
    
    return results
```

### Database Performance Impact

**Testing Database Load:**
```python
import psycopg2
import time

def test_database_performance_under_load():
    # Monitor database connections during API load test
    db_connection = psycopg2.connect(
        host="localhost",
        database="test_db", 
        user="test_user",
        password="test_pass"
    )
    
    def get_db_stats():
        cursor = db_connection.cursor()
        cursor.execute("""
            SELECT 
                count(*) as active_connections,
                avg(query_duration) as avg_query_time
            FROM pg_stat_activity 
            WHERE state = 'active'
        """)
        return cursor.fetchone()
    
    # Baseline measurement
    baseline_stats = get_db_stats()
    
    # Start API load test
    tester = APIPerformanceTester("https://api.example.com")
    
    # Monitor during load test
    start_time = time.time()
    db_stats_during_load = []
    
    # Run load test in separate thread
    import threading
    def run_load_test():
        tester.load_test("/api/users", num_requests=1000, concurrent_users=50)
    
    load_thread = threading.Thread(target=run_load_test)
    load_thread.start()
    
    # Monitor database while load test runs
    while load_thread.is_alive():
        stats = get_db_stats()
        db_stats_during_load.append({
            'timestamp': time.time() - start_time,
            'connections': stats[0],
            'avg_query_time': stats[1]
        })
        time.sleep(5)  # Monitor every 5 seconds
    
    load_thread.join()
    
    # Analyze database impact
    max_connections = max(stat['connections'] for stat in db_stats_during_load)
    avg_query_time_under_load = sum(stat['avg_query_time'] for stat in db_stats_during_load) / len(db_stats_during_load)
    
    print(f"Baseline connections: {baseline_stats[0]}")
    print(f"Max connections under load: {max_connections}")
    print(f"Average query time under load: {avg_query_time_under_load}")
    
    # Performance assertions
    assert max_connections < 100, "Too many database connections"
    assert avg_query_time_under_load < 1.0, "Database queries too slow under load"
```

### Memory and Resource Monitoring

**System Resource Monitoring:**
```python
import psutil
import time
import threading

class ResourceMonitor:
    def __init__(self):
        self.monitoring = False
        self.stats = []
    
    def start_monitoring(self):
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_resources)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        self.monitoring = False
        self.monitor_thread.join()
        return self.analyze_stats()
    
    def _monitor_resources(self):
        while self.monitoring:
            stats = {
                'timestamp': time.time(),
                'cpu_percent': psutil.cpu_percent(),
                'memory_percent': psutil.virtual_memory().percent,
                'disk_io': psutil.disk_io_counters(),
                'network_io': psutil.net_io_counters(),
                'process_count': len(psutil.pids())
            }
            self.stats.append(stats)
            time.sleep(1)  # Monitor every second
    
    def analyze_stats(self):
        if not self.stats:
            return {}
        
        return {
            'avg_cpu': sum(s['cpu_percent'] for s in self.stats) / len(self.stats),
            'max_cpu': max(s['cpu_percent'] for s in self.stats),
            'avg_memory': sum(s['memory_percent'] for s in self.stats) / len(self.stats),
            'max_memory': max(s['memory_percent'] for s in self.stats),
            'duration': len(self.stats)
        }

def test_resource_usage_during_load():
    monitor = ResourceMonitor()
    monitor.start_monitoring()
    
    # Run performance test
    tester = APIPerformanceTester("https://api.example.com")
    results = tester.load_test("/api/users", num_requests=500, concurrent_users=25)
    
    resource_stats = monitor.stop_monitoring()
    
    # Assertions
    assert resource_stats['max_cpu'] < 80, f"CPU usage too high: {resource_stats['max_cpu']}%"
    assert resource_stats['max_memory'] < 85, f"Memory usage too high: {resource_stats['max_memory']}%"
    
    print(f"Resource usage - CPU: {resource_stats['avg_cpu']:.1f}%, Memory: {resource_stats['avg_memory']:.1f}%")
```

### Performance Testing Best Practices

**1. Realistic Test Data:**
```python
def generate_realistic_test_data():
    """Generate realistic data for performance testing"""
    test_users = []
    
    for i in range(10000):  # Generate 10k test users
        user = {
            "name": f"User{i:05d}",
            "email": f"user{i:05d}@example.com",
            "age": random.randint(18, 80),
            "city": random.choice(["New York", "London", "Tokyo", "Paris"]),
            "signup_date": fake.date_between(start_date='-2y', end_date='today')
        }
        test_users.append(user)
    
    return test_users
```

**2. Performance Baseline Testing:**
```python
def establish_performance_baseline():
    """Run baseline performance tests to establish benchmarks"""
    baseline_tests = [
        {"endpoint": "/api/users", "expected_avg_response": 0.5, "expected_p95": 1.0},
        {"endpoint": "/api/users/123", "expected_avg_response": 0.3, "expected_p95": 0.8},
        {"endpoint": "/api/orders", "expected_avg_response": 1.0, "expected_p95": 2.0},
    ]
    
    tester = APIPerformanceTester("https://api.example.com")
    
    for test in baseline_tests:
        results = tester.load_test(test["endpoint"], num_requests=100, concurrent_users=10)
        
        assert results['avg_response_time'] <= test["expected_avg_response"], \
            f"Baseline failure - {test['endpoint']} avg response time: {results['avg_response_time']}"
        
        assert results['p95_response_time'] <= test["expected_p95"], \
            f"Baseline failure - {test['endpoint']} P95 response time: {results['p95_response_time']}"
```

**3. Continuous Performance Testing:**
```python
# pytest conftest.py
import pytest

@pytest.fixture(scope="session")
def performance_monitor():
    """Session-wide performance monitoring"""
    monitor = ResourceMonitor()
    monitor.start_monitoring()
    
    yield monitor
    
    # After all tests complete
    stats = monitor.stop_monitoring()
    
    # Log performance summary
    print(f"\nSession Performance Summary:")
    print(f"Average CPU: {stats['avg_cpu']:.1f}%")
    print(f"Max Memory: {stats['max_memory']:.1f}%")
    
    # Fail if resource usage was too high during entire test session
    assert stats['max_cpu'] < 90, "CPU usage exceeded limits during test session"
    assert stats['max_memory'] < 90, "Memory usage exceeded limits during test session"
```

---

## üß† Interview Q&A for API Testing

### Basic API Testing Questions

**1. What is API testing and why is it important?**

**Answer:** API testing is a type of software testing that focuses on verifying Application Programming Interfaces (APIs) directly, rather than testing through the user interface. 

**Why it's important:**
- **Early bug detection:** Find issues before UI development
- **Faster feedback:** APIs respond faster than UI tests  
- **Better coverage:** Test business logic directly
- **Platform independence:** Same API serves multiple clients
- **Cost-effective:** Cheaper to fix bugs at API level

**2. What are the different types of APIs you have tested?**

**Answer:** 
- **REST APIs:** Most common, uses HTTP methods (GET, POST, PUT, DELETE)
- **SOAP APIs:** XML-based with strict protocols, often used in enterprise
- **GraphQL APIs:** Query language that allows clients to request specific data
- **WebSocket APIs:** Real-time bidirectional communication
- **gRPC APIs:** High-performance RPC framework using Protocol Buffers

**3. Explain the difference between API testing and UI testing.**

**Answer:**
| **API Testing** | **UI Testing** |
|----------------|----------------|
| Tests business logic directly | Tests through user interface |
| Faster execution | Slower due to UI rendering |
| Data-focused | User experience focused |
| No browser dependency | Requires browser |
| Tests backend functionality | Tests frontend + backend |
| More stable (less flaky) | Can be flaky due to UI changes |

**4. How do you handle authentication in API testing?**

**Answer:** There are several authentication methods I've worked with:

```python
# Different authentication methods

# 1. Basic Authentication
import base64
credentials = base64.b64encode("username:password".encode()).decode()
headers = {"Authorization": f"Basic {credentials}"}

# 2. Bearer Token
headers = {"Authorization": f"Bearer {access_token}"}

# 3. API Key
headers = {"X-API-Key": "your_api_key"}

# 4. OAuth 2.0 (get token first, then use it)
token_response = requests.post("/oauth/token", data={
    "grant_type": "client_credentials",
    "client_id": "your_client_id", 
    "client_secret": "your_client_secret"
})
access_token = token_response.json()["access_token"]
headers = {"Authorization": f"Bearer {access_token}"}
```

**5. What are the common HTTP status codes you validate in API testing?**

**Answer:**
- **200 OK:** Request successful
- **201 Created:** Resource created successfully  
- **400 Bad Request:** Invalid request format/data
- **401 Unauthorized:** Authentication required
- **403 Forbidden:** Access denied (user authenticated but no permission)
- **404 Not Found:** Resource doesn't exist
- **500 Internal Server Error:** Server-side error

### Intermediate API Testing Questions

**6. How do you design test cases for API testing?**

**Answer:** I follow a systematic approach:

**1. Functional Test Cases:**
- Valid input data with expected outcomes
- Invalid input data with error handling
- Boundary value testing
- Missing required fields
- Extra fields in request

**2. Authentication & Authorization:**
- Valid credentials
- Invalid credentials  
- Expired tokens
- Access to restricted resources

**3. Data Validation:**
- Request/response schema validation
- Data type validation
- Field length validation
- Special characters handling

**Example Test Case:**
```python
def test_create_user_api():
    # Positive test case
    valid_data = {
        "name": "John Doe",
        "email": "john@example.com", 
        "age": 25
    }
    response = requests.post("/api/users", json=valid_data)
    assert response.status_code == 201
    assert response.json()["name"] == "John Doe"
    
    # Negative test case - missing required field
    invalid_data = {"name": "John Doe"}  # missing email
    response = requests.post("/api/users", json=invalid_data)
    assert response.status_code == 400
    assert "email" in response.json()["error"]
```

**7. How do you handle dynamic data in API testing?**

**Answer:** Dynamic data requires special handling strategies:

```python
# Strategy 1: Create your own test data
def test_with_created_data():
    # Create test user
    user_data = {"name": "TestUser", "email": "test@example.com"}
    user_response = requests.post("/api/users", json=user_data)
    user_id = user_response.json()["id"]
    
    # Use created user ID in subsequent tests
    response = requests.get(f"/api/users/{user_id}")
    assert response.status_code == 200

# Strategy 2: Use parameterized tests
@pytest.mark.parametrize("name,email,expected_status", [
    ("Valid User", "valid@test.com", 201),
    ("", "valid@test.com", 400),  # Empty name
    ("Valid User", "invalid-email", 400),  # Invalid email
])
def test_user_creation(name, email, expected_status):
    response = requests.post("/api/users", json={"name": name, "email": email})
    assert response.status_code == expected_status
```

**8. Explain how you would test a REST API with CRUD operations.**

**Answer:** I test CRUD operations systematically:

```python
class TestUserCRUD:
    def setUp(self):
        self.base_url = "https://api.example.com"
        self.created_user_id = None
    
    def test_create_user(self):
        # CREATE - POST
        user_data = {"name": "Test User", "email": "test@example.com"}
        response = requests.post(f"{self.base_url}/users", json=user_data)
        
        assert response.status_code == 201
        user = response.json()
        assert "id" in user
        assert user["name"] == user_data["name"]
        
        self.created_user_id = user["id"]
        return user["id"]
    
    def test_read_user(self):
        # READ - GET
        user_id = self.test_create_user()
        
        response = requests.get(f"{self.base_url}/users/{user_id}")
        assert response.status_code == 200
        
        user = response.json()
        assert user["id"] == user_id
        assert "name" in user
        assert "email" in user
    
    def test_update_user(self):
        # UPDATE - PUT
        user_id = self.test_create_user()
        
        update_data = {"name": "Updated Name"}
        response = requests.put(f"{self.base_url}/users/{user_id}", json=update_data)
        
        assert response.status_code == 200
        updated_user = response.json()
        assert updated_user["name"] == "Updated Name"
    
    def test_delete_user(self):
        # DELETE
        user_id = self.test_create_user()
        
        response = requests.delete(f"{self.base_url}/users/{user_id}")
        assert response.status_code == 204
        
        # Verify deletion
        get_response = requests.get(f"{self.base_url}/users/{user_id}")
        assert get_response.status_code == 404
```

**9. How do you test API performance?**

**Answer:** I use multiple approaches for performance testing:

```python
# 1. Response time validation
def test_response_time():
    start_time = time.time()
    response = requests.get("/api/users")
    end_time = time.time()
    
    assert response.status_code == 200
    assert (end_time - start_time) < 2.0  # Response under 2 seconds

# 2. Load testing with concurrent users
def test_load_performance():
    def make_request():
        return requests.get("/api/users")
    
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = [executor.submit(make_request) for _ in range(100)]
        results = [future.result() for future in futures]
    
    success_count = sum(1 for r in results if r.status_code == 200)
    assert success_count >= 95  # 95% success rate

# 3. Using performance testing tools
# - Apache Bench (ab)
# - Locust
# - JMeter
```

**10. What is the difference between API testing and Integration testing?**

**Answer:**
| **API Testing** | **Integration Testing** |
|----------------|------------------------|
| Tests individual APIs | Tests interaction between systems |
| Focuses on single service | Tests end-to-end workflows |
| Validates API contracts | Validates data flow between services |
| Unit-level testing | System-level testing |

**Example:**
- **API Testing:** Test `/api/users POST` endpoint individually
- **Integration Testing:** Test user creation ‚Üí email notification ‚Üí database update workflow

### Advanced API Testing Questions

**11. How do you implement API test automation framework?**

**Answer:** I design frameworks with these components:

```python
# Framework structure
api_framework/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py
‚îÇ   ‚îî‚îÄ‚îÄ environments.yaml
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_users.py
‚îÇ   ‚îî‚îÄ‚îÄ test_orders.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ api_client.py
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py
‚îÇ   ‚îî‚îÄ‚îÄ assertions.py
‚îú‚îÄ‚îÄ reports/
‚îî‚îÄ‚îÄ requirements.txt

# Base API client
class APIClient:
    def __init__(self, base_url, auth_token=None):
        self.base_url = base_url
        self.session = requests.Session()
        if auth_token:
            self.session.headers.update({"Authorization": f"Bearer {auth_token}"})
    
    def get(self, endpoint, **kwargs):
        return self._make_request('GET', endpoint, **kwargs)
    
    def post(self, endpoint, **kwargs):
        return self._make_request('POST', endpoint, **kwargs)
    
    def _make_request(self, method, endpoint, **kwargs):
        url = f"{self.base_url}{endpoint}"
        headers = {**self.default_headers, **kwargs.pop('headers', {})}
        
        response = self.session.request(method, url, headers=headers, **kwargs)
        
        # Add custom assertions
        assert response.status_code < 500, f"Server error: {response.status_code}"
        
        return response

# Usage
api = APITestFramework('https://api.example.com')
api.set_auth_token('your-token')
response = api.get('/users')
```

**12. How do you handle API versioning in testing?**

**Answer:** I test multiple API versions simultaneously:

```python
@pytest.mark.parametrize("api_version", ["v1", "v2", "v3"])
def test_get_user_across_versions(api_version):
    response = requests.get(f"/api/{api_version}/users/123")
    assert response.status_code == 200
    
    # Version-specific validations
    user_data = response.json()
    if api_version == "v1":
        assert "name" in user_data
    elif api_version == "v2":
        assert "full_name" in user_data
        assert "created_at" in user_data

# Backward compatibility testing
def test_backward_compatibility():
    v1_response = requests.get("/api/v1/users/123")
    v2_response = requests.get("/api/v2/users/123")
    
    # Ensure essential data is available in both versions
    assert v1_response.json()["id"] == v2_response.json()["id"]
```

**13. Explain Contract Testing and when you would use it.**

**Answer:** Contract testing ensures services can communicate by testing the "contract" between consumer and provider.

**When to use:**
- Microservices architecture
- Multiple teams developing different services
- API changes frequently
- Need to prevent breaking changes

```python
# Consumer-driven contract with Pact
def test_user_service_contract():
    expected_user = {
        "id": Matcher.like(123),
        "name": Matcher.like("John Doe"),
        "email": Matcher.regex(r".*@.*\.com")
    }
    
    pact.given("User 123 exists") \
        .upon_receiving("Get user request") \
        .with_request("GET", "/users/123") \
        .will_respond_with(200, body=expected_user)
```

**14. How do you test APIs with large datasets or pagination?**

**Answer:**

```python
def test_pagination():
    # Test first page
    response = requests.get("/api/users?page=1&limit=10")
    assert response.status_code == 200
    
    data = response.json()
    assert len(data["users"]) <= 10
    assert "total_count" in data
    assert "current_page" in data
    assert "total_pages" in data
    
    # Test edge cases
    # Empty page
    last_page = data["total_pages"]
    response = requests.get(f"/api/users?page={last_page + 1}&limit=10")
    assert response.status_code == 200
    assert len(response.json()["users"]) == 0
    
    # Invalid page
    response = requests.get("/api/users?page=-1&limit=10")
    assert response.status_code == 400

def test_large_dataset_performance():
    # Test with large page size
    response = requests.get("/api/users?limit=1000")
    assert response.status_code == 200
    assert response.elapsed.total_seconds() < 5.0  # Should respond within 5 seconds
```

**15. What security testing do you perform on APIs?**

**Answer:** I test for common security vulnerabilities:

```python
# 1. Authentication bypass
def test_unauthorized_access():
    response = requests.get("/api/admin/users")  # No auth header
    assert response.status_code == 401

# 2. SQL injection
def test_sql_injection():
    malicious_input = "'; DROP TABLE users; --"
    response = requests.get(f"/api/users?name={malicious_input}")
    assert response.status_code in [400, 422]  # Should be rejected

# 3. XSS prevention
def test_xss_prevention():
    xss_payload = "<script>alert('xss')</script>"
    response = requests.post("/api/users", json={"name": xss_payload})
    
    if response.status_code == 201:
        # If creation succeeded, ensure script is sanitized
        user_data = response.json()
        assert "<script>" not in user_data["name"]

# 4. Rate limiting
def test_rate_limiting():
    for i in range(101):  # Exceed rate limit
        response = requests.get("/api/users")
        if response.status_code == 429:  # Too Many Requests
            break
    assert response.status_code == 429

# 5. HTTPS enforcement
def test_https_enforcement():
    response = requests.get("http://api.example.com/users", allow_redirects=False)
    assert response.status_code == 301  # Should redirect to HTTPS
```

### Scenario-Based Questions

**16. How would you test an API that depends on external services?**

**Answer:** I use mocking and contract testing:

```python
# 1. Mock external services
@responses.activate
def test_with_external_dependency():
    # Mock external payment service
    responses.add(
        responses.POST,
        "https://payment-service.com/charge",
        json={"transaction_id": "12345", "status": "success"},
        status=200
    )
    
    # Test our API that calls payment service
    order_data = {"amount": 100, "currency": "USD"}
    response = requests.post("/api/orders", json=order_data)
    
    assert response.status_code == 201
    assert response.json()["payment_status"] == "success"

# 2. Test with circuit breaker
def test_external_service_failure():
    # Simulate external service being down
    with patch('external_service.call') as mock_service:
        mock_service.side_effect = ConnectionError("Service unavailable")
        
        response = requests.post("/api/orders", json={"amount": 100})
        assert response.status_code == 503  # Service unavailable
        assert "external service" in response.json()["error"].lower()
```

**17. Describe your approach to testing a microservices API ecosystem.**

**Answer:** I use a multi-layered testing approach:

```python
# 1. Individual service testing
def test_user_service():
    response = requests.get("http://user-service/api/users/123")
    assert response.status_code == 200

# 2. Service-to-service communication
def test_service_integration():
    # Create user in user service
    user_response = requests.post("http://user-service/api/users", 
                                 json={"name": "Test User"})
    user_id = user_response.json()["id"]
    
    # Create order in order service (calls user service internally)
    order_response = requests.post("http://order-service/api/orders",
                                  json={"user_id": user_id, "product": "laptop"})
    assert order_response.status_code == 201

# 3. End-to-end workflow testing
def test_complete_purchase_workflow():
    # User registration ‚Üí Product selection ‚Üí Payment ‚Üí Order fulfillment
    steps = [
        ("POST", "user-service", "/api/users", {"name": "Customer"}),
        ("POST", "product-service", "/api/cart", {"user_id": user_id, "product_id": 1}),
        ("POST", "payment-service", "/api/payments", {"amount": 100}),
        ("POST", "order-service", "/api/orders", {"cart_id": cart_id})
    ]
    
    for method, service, endpoint, data in steps:
        response = requests.request(method, f"http://{service}{endpoint}", json=data)
        assert response.status_code in [200, 201]
```

**18. How do you test real-time APIs or WebSocket connections?**

**Answer:** For manual testing of real-time APIs and WebSocket connections, I use these approaches:

**Manual WebSocket Testing Methods:**

**1. Browser Developer Tools Method:**
```javascript
// Manual WebSocket testing in browser console
const ws = new WebSocket('ws://localhost:8080/ws');

ws.onopen = function(event) {
    console.log('‚úÖ WebSocket connection established');
    // Send test message
    ws.send(JSON.stringify({type: "ping", data: "test"}));
};

ws.onmessage = function(event) {
    const message = JSON.parse(event.data);
    console.log('üì® Message received:', message);
    
    // Manual validation checks
    if (message.type === 'pong') {
        console.log('‚úÖ Ping-pong test successful');
    }
};

ws.onerror = function(error) {
    console.error('‚ùå WebSocket error:', error);
};

ws.onclose = function(event) {
    console.log('üîå WebSocket connection closed:', event.code, event.reason);
};

// Manual test: Send different message types
setTimeout(() => {
    ws.send(JSON.stringify({type: "chat", message: "Hello World"}));
}, 2000);
```

**2. Postman WebSocket Testing:**
- Create new WebSocket request in Postman
- Connect to `ws://localhost:8080/ws`
- Manual test scenarios:
  - Connection establishment
  - Send/receive messages
  - Connection persistence
  - Error handling

**3. Manual Browser Testing Checklist:**
```
Real-time API Testing Checklist:
‚úÖ Connection establishes successfully
‚úÖ Authentication works (if required)
‚úÖ Messages send correctly
‚úÖ Messages received in proper format
‚úÖ Real-time updates work
‚úÖ Connection handles network interruptions
‚úÖ Proper error messages displayed
‚úÖ Connection cleanup on page close
‚úÖ Multiple concurrent connections work
‚úÖ Rate limiting enforced (if applicable)
```

**4. Manual Testing Scenarios:**
- **Connection Testing:** Open multiple browser tabs, verify each can connect
- **Message Broadcasting:** Send message from one client, verify others receive it
- **Network Interruption:** Disconnect/reconnect internet, check auto-reconnection
- **Load Testing:** Open many browser tabs to test concurrent connections
- **Authentication:** Test connection with valid/invalid tokens

### Problem-Solving Questions

**19. An API test is failing intermittently. How would you debug it?**

**Answer:** I follow a systematic debugging approach:

```python
# 1. Add detailed logging
import logging

def test_flaky_api():
    logger = logging.getLogger(__name__)
    
    for attempt in range(3):  # Retry mechanism
        try:
            logger.info(f"Attempt {attempt + 1}")
            
            start_time = time.time()
            response = requests.get("/api/users", timeout=10)
            end_time = time.time()
            
            logger.info(f"Response time: {end_time - start_time}s")
            logger.info(f"Status code: {response.status_code}")
            
            assert response.status_code == 200
            break
            
        except Exception as e:
            logger.error(f"Attempt {attempt + 1} failed: {e}")
            if attempt == 2:  # Last attempt
                raise
            time.sleep(2)  # Wait before retry

# 2. Check for timing issues
def test_with_wait_conditions():
    # Create resource
    response = requests.post("/api/users", json={"name": "Test"})
    user_id = response.json()["id"]
    
    # Wait for eventual consistency
    max_wait = 10
    for _ in range(max_wait):
        get_response = requests.get(f"/api/users/{user_id}")
        if get_response.status_code == 200:
            break
        time.sleep(1)
    else:
        raise AssertionError("User not found after creation")

# 3. Environment-specific checks
def test_environment_specific():
    env = os.getenv("TEST_ENV", "staging")
    
    if env == "production":
        # More lenient timeouts in production
        timeout = 30
    else:
        timeout = 10
    
    response = requests.get("/api/users", timeout=timeout)
    assert response.status_code == 200
```

**20. How would you implement data-driven API testing?**

**Answer:**

```python
# 1. Using CSV data
import csv
import pytest

def load_test_data():
    test_cases = []
    with open('test_data.csv', 'r') as file:
        reader = csv.DictReader(file)
        for row in reader:
            test_cases.append((row['name'], row['email'], int(row['expected_status'])))
    return test_cases

@pytest.mark.parametrize("name,email,expected_status", 
                         load_test_data())
def test_user_creation_data_driven(name, email, expected_status):
    response = requests.post('/api/users', json={
        'name': name,
        'email': email,
        'age': age
    })
    assert response.status_code == expected_status
```

### Best Practices Summary

1. **Test Organization**
   - Group related tests in classes
   - Use descriptive test names
   - Implement proper setup/teardown

2. **Assertions**
   - Test status codes
   - Validate response structure
   - Check data types and values
   - Verify headers

3. **Data Management**
   - Use factories for test data
   - Implement cleanup strategies
   - Isolate test data

4. **Error Handling**
   - Test all error scenarios
   - Validate error messages
   - Check error response structure

5. **Performance**
   - Set response time thresholds
   - Monitor resource usage
   - Test under load

6. **Security**
   - Test authentication/authorization
   - Validate input sanitization
   - Check for vulnerabilities

7. **Maintenance**
   - Keep tests independent
   - Use configuration management
   - Implement retry logic for flaky tests

---

## üìé Bonus Topics

### GraphQL vs REST: Testing Differences

**REST API Testing:**
```python
# REST - Multiple endpoints
def test_rest_user_operations():
    # Get user
    user_response = requests.get("/api/users/123")
    
    # Get user's posts  
    posts_response = requests.get("/api/users/123/posts")
    
    # Get user's comments
    comments_response = requests.get("/api/users/123/comments")
    
    # Multiple network calls
    assert user_response.status_code == 200
    assert posts_response.status_code == 200
    assert comments_response.status_code == 200
```

**GraphQL API Testing:**
```python
# GraphQL - Single endpoint, custom queries
def test_graphql_user_operations():
    query = """
    query GetUserWithPosts($userId: ID!) {
        user(id: $userId) {
            id
            name
            email
            posts {
                id
                title
                content
                comments {
                    id
                    text
                    author
                }
            }
        }
    }
    """
    
    variables = {"userId": "123"}
    
    response = requests.post("/graphql", json={
        "query": query,
        "variables": variables
    })
    
    assert response.status_code == 200
    data = response.json()
    
    # GraphQL-specific validations
    assert "errors" not in data
    assert "data" in data
    assert data["data"]["user"] is not None

# GraphQL Error Testing
def test_graphql_errors():
    invalid_query = """
    query {
        user(id: "invalid") {
            nonExistentField
        }
    }
    """
    
    response = requests.post("/graphql", json={"query": invalid_query})
    assert response.status_code == 200  # GraphQL returns 200 even for errors
    
    data = response.json()
    assert "errors" in data
    assert len(data["errors"]) > 0
```

**Key Differences:**
| **REST** | **GraphQL** |
|----------|-------------|
| Multiple endpoints | Single endpoint |
| Over-fetching common | Fetch exactly what you need |
| HTTP status codes for errors | Always returns 200, errors in response body |
| Caching easier | Caching more complex |
| Multiple requests for related data | Single request for complex data |

### Webhooks Testing

**What are Webhooks:** HTTP callbacks that notify your system when events happen in external systems.

**Testing Webhook Reception:**
```python
from flask import Flask, request
import threading
import requests
import time

app = Flask(__name__)
received_webhooks = []

@app.route('/webhook', methods=['POST'])
def webhook_receiver():
    """Webhook endpoint to receive test webhooks"""
    webhook_data = request.get_json()
    received_webhooks.append({
        'timestamp': time.time(),
        'data': webhook_data,
        'headers': dict(request.headers)
    })
    return 'OK', 200

def test_webhook_delivery():
    # Start webhook receiver server
    webhook_thread = threading.Thread(
        target=lambda: app.run(host='localhost', port=5000, debug=False)
    )
    webhook_thread.daemon = True
    webhook_thread.start()
    
    time.sleep(2)  # Allow server to start
    
    # Configure webhook in the system under test
    webhook_config = {
        'url': 'http://localhost:5000/webhook',
        'events': ['user.created', 'user.updated']
    }
    
    config_response = requests.post('/api/webhooks', json=webhook_config)
    assert config_response.status_code == 201
    
    # Trigger an event that should send a webhook
    user_data = {'name': 'Test User', 'email': 'test@example.com'}
    user_response = requests.post('/api/users', json=user_data)
    assert user_response.status_code == 201
    
    # Wait for webhook delivery
    time.sleep(3)
    
    # Verify webhook was received
    assert len(received_webhooks) > 0
    
    webhook = received_webhooks[0]
    assert webhook['data']['event'] == 'user.created'
    assert webhook['data']['user']['email'] == 'test@example.com'
```

**Testing Webhook Security:**
```python
import hmac
import hashlib

def test_webhook_signature_validation():
    """Test webhook signature verification"""
    secret = "webhook_secret_key"
    payload = '{"event": "user.created", "user_id": 123}'
    
    # Calculate expected signature
    signature = hmac.new(
        secret.encode('utf-8'),
        payload.encode('utf-8'),
        hashlib.sha256
    ).hexdigest()
    
    headers = {
        'X-Webhook-Signature': f'sha256={signature}',
        'Content-Type': 'application/json'
    }
    
    # Send webhook with valid signature
    response = requests.post('http://localhost:5000/webhook', 
                           data=payload, headers=headers)
    assert response.status_code == 200
    
    # Test with invalid signature
    headers['X-Webhook-Signature'] = 'sha256=invalid_signature'
    response = requests.post('http://localhost:5000/webhook',
                           data=payload, headers=headers)
    assert response.status_code == 401  # Should reject invalid signature
```

### API Versioning Strategies

**1. URL Path Versioning:**
```python
def test_url_path_versioning():
    # Test multiple versions
    versions = ['v1', 'v2', 'v3']
    
    for version in versions:
        response = requests.get(f'/api/{version}/users/123')
        assert response.status_code == 200
        
        user_data = response.json()
        
        # Version-specific field validation
        if version == 'v1':
            assert 'name' in user_data
            assert 'created_date' not in user_data
        elif version == 'v2':
            assert 'full_name' in user_data
            assert 'created_date' in user_data
        elif version == 'v3':
            assert 'first_name' in user_data
            assert 'last_name' in user_data
            assert 'created_at' in user_data
```

**2. Header Versioning:**
```python
def test_header_versioning():
    versions = [
        ('application/vnd.api.v1+json', 'v1'),
        ('application/vnd.api.v2+json', 'v2'),
        ('application/vnd.api.v3+json', 'v3')
    ]
    
    for content_type, version in versions:
        headers = {'Accept': content_type}
        response = requests.get('/api/users/123', headers=headers)
        
        assert response.status_code == 200
        assert response.headers['Content-Type'].startswith(content_type)
```

**3. Query Parameter Versioning:**
```python
def test_query_parameter_versioning():
    versions = ['1.0', '2.0', '3.0']
    
    for version in versions:
        response = requests.get(f'/api/users/123?version={version}')
        assert response.status_code == 200
        
        user_data = response.json()
        assert user_data['api_version'] == version
```

### API Gateway Testing

**Testing Rate Limiting at Gateway:**
```python
def test_api_gateway_rate_limiting():
    """Test rate limiting at API Gateway level"""
    
    # Test normal rate limit
    success_count = 0
    rate_limited_count = 0
    
    for i in range(150):  # Exceed rate limit
        response = requests.get('/api/users', headers={
            'X-API-Key': 'test-api-key'
        })
        
        if response.status_code == 200:
            success_count += 1
        elif response.status_code == 429:  # Too Many Requests
            rate_limited_count += 1
            
            # Verify rate limit headers
            assert 'X-RateLimit-Limit' in response.headers
            assert 'X-RateLimit-Remaining' in response.headers
            assert 'Retry-After' in response.headers
        
        time.sleep(0.1)  # Small delay between requests
    
    assert rate_limited_count > 0, "Rate limiting not triggered"
    assert success_count > 0, "No successful requests"
```

**Testing Load Balancing:**
```python
def test_load_balancing():
    """Test that requests are distributed across multiple servers"""
    
    server_responses = []
    
    for i in range(100):
        response = requests.get('/api/health')
        assert response.status_code == 200
        
        # Capture server identifier from response
        server_id = response.headers.get('X-Server-ID')
        if server_id:
            server_responses.append(server_id)
    
    # Verify requests were distributed across multiple servers
    unique_servers = set(server_responses)
    assert len(unique_servers) > 1, "Load balancing not working - all requests went to same server"
    
    # Verify relatively even distribution
    server_counts = {server: server_responses.count(server) for server in unique_servers}
    max_requests = max(server_counts.values())
    min_requests = min(server_counts.values())
    
    # Difference shouldn't be more than 20% of total requests
    assert (max_requests - min_requests) < len(server_responses) * 0.2
```

### Manual API Testing Integration in Development Workflow

**Manual Testing Process Integration:**

**1. Development Phase Integration:**
```
Manual Testing Workflow:
1. Developer completes API feature
2. Manual tester reviews API documentation
3. Create manual test cases in Postman
4. Execute test scenarios manually
5. Document results and report issues
6. Re-test fixes before code merge
```

**2. Manual Testing Documentation:**
```
Test Documentation Template:
- Feature: [API Feature Name]
- Endpoints: [List of endpoints]
- Test Scenarios: [Manual test cases]
- Test Data: [Required test data sets]
- Expected Results: [Success criteria]
- Actual Results: [Test execution results]
- Issues Found: [Bug reports with screenshots]
- Status: [Pass/Fail/Blocked]
```

**3. Manual Test Execution Tracking:**
```
Manual Testing Checklist:
‚úÖ Smoke Tests (Critical path verification)
   - Login/Authentication works
   - Core CRUD operations functional
   - Basic error handling

‚úÖ Functional Tests (Feature verification)
   - All documented scenarios tested
   - Edge cases explored
   - Data validation confirmed

‚úÖ Integration Tests (Cross-system verification)
   - External API dependencies tested
   - Database operations verified
   - End-to-end workflows confirmed

‚úÖ Security Tests (Manual security checks)
   - Authentication bypass attempts
   - Input validation testing
   - Error message verification
```

**4. Manual Testing Environments:**
```
Environment Setup:
- Development: http://dev-api.example.com
- Staging: https://staging-api.example.com
- Production: https://api.example.com

Manual Environment Testing:
1. Verify each environment accessibility
2. Test configuration differences
3. Validate data consistency
4. Check environment-specific features
5. Document environment-specific issues
```

**5. Manual Test Result Reporting:**
```
Manual Test Report Template:
================================
API Testing Report
Date: [Test Date]
Tester: [Tester Name]
Environment: [Test Environment]
Build Version: [Version Number]

Test Summary:
- Total Test Cases: X
- Passed: X
- Failed: X
- Blocked: X
- Not Executed: X

Critical Issues:
1. [Issue description with severity]
2. [Issue description with severity]

Recommendations:
- [Testing recommendations]
- [Environment improvements]
- [Process suggestions]
================================
```

### Manual API Testing Environment Setup

**Manual Environment Configuration:**

**1. Local Testing Environment Setup:**
```
Local Development Testing:
1. Install Postman for API testing
2. Configure environment variables:
   - base_url: http://localhost:3000
   - auth_token: [development token]
   - timeout: 30000ms

3. Set up test data:
   - Create test user accounts
   - Prepare sample data sets
   - Document test credentials

4. Manual Testing Checklist:
   ‚úÖ API server is running locally
   ‚úÖ Database is accessible and populated
   ‚úÖ Authentication service is working
   ‚úÖ All dependencies are available
```

**2. Remote Environment Testing:**
```
Staging Environment Testing:
1. Configure Postman environments:
   - staging_url: https://staging-api.example.com
   - staging_auth: [staging authentication]
   - staging_timeout: 10000ms

2. Environment-Specific Testing:
   ‚úÖ SSL certificates are valid
   ‚úÖ CORS settings work correctly
   ‚úÖ Rate limiting is configured
   ‚úÖ Error handling works properly

3. Cross-Environment Consistency:
   ‚úÖ Same endpoints available
   ‚úÖ Same response formats
   ‚úÖ Compatible authentication
   ‚úÖ Consistent error messages
```

**3. Manual Testing Data Management:**
```
Test Data Strategy:
1. Preparation Phase:
   - Create dedicated test accounts
   - Prepare clean datasets
   - Document test data relationships
   - Set up test scenario data

2. Execution Phase:
   - Use consistent test data
   - Track data changes during testing
   - Document any data dependencies
   - Clean up after test execution

3. Data Cleanup Process:
   - Remove test data after execution
   - Reset database to clean state
   - Verify no test data leakage
   - Document cleanup procedures
```

**4. Manual Environment Validation:**
```
Environment Health Check:
1. Connectivity Tests:
   - GET /health endpoint
   - Verify response time <2 seconds
   - Check status code = 200
   - Validate response format

2. Authentication Tests:
   - Test valid credentials
   - Test invalid credentials  
   - Verify token expiration
   - Check permission levels

3. Performance Baseline:
   - Measure response times
   - Test concurrent connections
   - Monitor error rates
   - Document baseline metrics
```

### API Monitoring and Observability

**Health Check Testing:**
```python
def test_api_health_endpoints():
    """Test various health check endpoints"""
    
    # Basic health check
    response = requests.get('/health')
    assert response.status_code == 200
    assert response.json()['status'] == 'healthy'
    
    # Detailed health check
    response = requests.get('/health/detailed')
    assert response.status_code == 200
    
    health_data = response.json()
    assert 'database' in health_data
    assert 'cache' in health_data
    assert 'external_services' in health_data
    
    # All components should be healthy
    for component, status in health_data.items():
        assert status['status'] == 'healthy', f"{component} is not healthy"

def test_metrics_endpoint():
    """Test metrics endpoint for monitoring"""
    response = requests.get('/metrics')
    assert response.status_code == 200
    
    # Check for important metrics
    metrics_text = response.text
    assert 'api_requests_total' in metrics_text
    assert 'api_request_duration_seconds' in metrics_text
    assert 'api_errors_total' in metrics_text
```

**Distributed Tracing Testing:**
```python
def test_distributed_tracing():
    """Test that distributed tracing headers are propagated"""
    
    trace_id = str(uuid.uuid4())
    span_id = str(uuid.uuid4())
    
    headers = {
        'X-Trace-Id': trace_id,
        'X-Span-Id': span_id,
        'X-Parent-Span-Id': 'root'
    }
    
    response = requests.get('/api/users/123', headers=headers)
    assert response.status_code == 200
    
    # Verify trace headers are returned
    assert response.headers.get('X-Trace-Id') == trace_id
    assert 'X-Span-Id' in response.headers
    
    # Test downstream service calls propagate tracing
    # This would require access to tracing system (Jaeger, Zipkin, etc.)
```

### API Documentation Testing

**OpenAPI/Swagger Validation:**
```python
import yaml
import requests
from openapi_spec_validator import validate_spec

def test_openapi_spec_validity():
    """Test that OpenAPI specification is valid"""
    
    # Get OpenAPI spec
    response = requests.get('/api/docs/openapi.json')
    assert response.status_code == 200
    
    spec = response.json()
    
    # Validate spec format
    validate_spec(spec)
    
    # Test that all endpoints in spec are accessible
    for path, methods in spec['paths'].items():
        for method in methods.keys():
            if method.upper() in ['GET', 'POST', 'PUT', 'DELETE']:
                # Basic connectivity test
                test_response = requests.request(method.upper(), f"/api{path}")
                # Should not return 404 (endpoint exists)
                assert test_response.status_code != 404

def test_api_documentation_examples():
    """Test that examples in API documentation work"""
    
    # Load OpenAPI spec
    spec_response = requests.get('/api/docs/openapi.json')
    spec = spec_response.json()
    
    # Test examples from spec
    for path, methods in spec['paths'].items():
        for method, details in methods.items():
            if 'requestBody' in details and 'examples' in details['requestBody'].get('content', {}).get('application/json', {}):
                examples = details['requestBody']['content']['application/json']['examples']
                
                for example_name, example_data in examples.items():
                    # Test each example
                    response = requests.request(
                        method.upper(),
                        f"/api{path}",
                        json=example_data.get('value')
                    )
                    
                    # Should return a valid response (not 400 for bad request)
                    assert response.status_code < 500, f"Example {example_name} failed for {method.upper()} {path}"
```

---

## Conclusion

This comprehensive API testing guide covers everything from basic concepts to advanced testing strategies, providing you with the knowledge and practical examples needed to excel in API testing. Whether you're a beginner starting your journey or an experienced professional looking to deepen your expertise, this guide serves as your complete reference.

**Key Takeaways:**
üéØ **Start with Fundamentals**
- Understand HTTP basics and API types
- Master authentication and authorization concepts
- Learn to validate status codes and response structures

üîß **Build Practical Skills**
- Choose the right tools for your needs (Postman, REST Assured, Python requests)
- Write maintainable and independent test cases
- Implement comprehensive error handling and data validation

üöÄ **Advance Your Expertise**
- Apply advanced techniques like contract testing and mocking
- Integrate security and performance testing into your strategy
- Master microservices and distributed systems testing

üíº **Prepare for Success**
- Use the interview questions to test your knowledge
- Practice with real-world scenarios and edge cases
- Stay updated with emerging technologies and best practices

**Next Steps:**
1. **Practice Hands-On:** Start with public APIs (JSONPlaceholder, GitHub API, OpenWeatherMap)
2. **Build Your Framework:** Create a reusable API testing framework using your preferred tools
3. **Explore Advanced Topics:** Dive deeper into contract testing, GraphQL, and microservices
4. **Join Communities:** Engage with API testing communities and forums
5. **Keep Learning:** Technology evolves rapidly - stay curious and keep updating your skills

**Resources for Continued Learning:**
- **APIs for Practice:** 
  - JSONPlaceholder (jsonplaceholder.typicode.com)
  - GitHub API (docs.github.com/en/rest)
  - OpenWeatherMap API (openweathermap.org/api)
  - Public APIs Collection (github.com/public-apis/public-apis)

- **Tools to Explore:**
  - Postman, Insomnia, REST Assured, Karate, Pact, WireMock, Locust

- **Communities:**
  - Ministry of Testing, Test Automation University, Stack Overflow

Remember: API testing is not just about sending requests and checking responses - it's about ensuring systems communicate reliably, securely, and efficiently. Think like both a developer and a user, consider edge cases, and always prioritize the end-user experience.

**Happy Testing! üöÄ**

*"The best API tests are those that give you confidence in your system's reliability, security, and performance - they're your safety net in the fast-paced world of software development."*